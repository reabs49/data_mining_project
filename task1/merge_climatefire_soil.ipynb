{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c90cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HWSD2_SMU_ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "COARSE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SAND",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SILT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CLAY",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TEXTURE_USDA",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TEXTURE_SOTER",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "BULK",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "REF_BULK",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ORG_CARBON",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PH_WATER",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TOTAL_N",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CN_RATIO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CEC_SOIL",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CEC_CLAY",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CEC_EFF",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TEB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BSAT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ALUM_SAT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ESP",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TCARBON_EQ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GYPSUM",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ELEC_COND",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "e066dbea-dc8c-4d73-8d39-616107d4f37f",
       "rows": [
        [
         "0",
         "31802",
         "8.93750000000026",
         "37.53749999999999",
         "11",
         "40",
         "41",
         "19",
         "9.0",
         "M",
         "1.4700000286102295",
         "1.690000057220459",
         "2.0370001792907715",
         "5.300000190734863",
         "1.5399999618530271",
         "14.0",
         "11",
         "26",
         "6.0",
         "5.0",
         "47",
         "21",
         "1",
         "0.0",
         "0.1000000014901161",
         "0"
        ],
        [
         "1",
         "31802",
         "8.93750000000026",
         "37.53749999999999",
         "9",
         "25",
         "53",
         "22",
         "7.0",
         "M",
         "1.4600000381469729",
         "1.7300000190734863",
         "1.8009999990463257",
         "5.800000190734863",
         "1.5700000524520874",
         "11.0",
         "15",
         "51",
         "14.0",
         "12.0",
         "65",
         "26",
         "3",
         "0.0",
         "0.1000000014901161",
         "0"
        ],
        [
         "2",
         "31805",
         "8.945833333333592",
         "37.53749999999999",
         "9",
         "87",
         "9",
         "4",
         "12.0",
         "C",
         "1.440000057220459",
         "1.2000000476837158",
         "0.628000020980835",
         "5.699999809265137",
         "0.5199999809265137",
         "13.0",
         "4",
         "33",
         "3.0",
         "3.0",
         "76",
         "6",
         "2",
         "0.0",
         "0.1000000014901161",
         "0"
        ],
        [
         "3",
         "31805",
         "8.945833333333592",
         "37.53749999999999",
         "5",
         "33",
         "31",
         "36",
         "5.0",
         "F",
         "1.350000023841858",
         "1.899999976158142",
         "1.9299999475479128",
         "6.099999904632568",
         "1.3200000524520874",
         "12.0",
         "20",
         "34",
         "15.0",
         "17.0",
         "82",
         "0",
         "1",
         "0.0",
         "1.600000023841858",
         "1"
        ],
        [
         "4",
         "31802",
         "8.912500000000257",
         "37.529166666666654",
         "11",
         "40",
         "41",
         "19",
         "9.0",
         "M",
         "1.4700000286102295",
         "1.690000057220459",
         "2.0370001792907715",
         "5.300000190734863",
         "1.5399999618530271",
         "14.0",
         "11",
         "26",
         "6.0",
         "5.0",
         "47",
         "21",
         "1",
         "0.0",
         "0.1000000014901161",
         "0"
        ]
       ],
       "shape": {
        "columns": 25,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HWSD2_SMU_ID</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>COARSE</th>\n",
       "      <th>SAND</th>\n",
       "      <th>SILT</th>\n",
       "      <th>CLAY</th>\n",
       "      <th>TEXTURE_USDA</th>\n",
       "      <th>TEXTURE_SOTER</th>\n",
       "      <th>BULK</th>\n",
       "      <th>...</th>\n",
       "      <th>CEC_SOIL</th>\n",
       "      <th>CEC_CLAY</th>\n",
       "      <th>CEC_EFF</th>\n",
       "      <th>TEB</th>\n",
       "      <th>BSAT</th>\n",
       "      <th>ALUM_SAT</th>\n",
       "      <th>ESP</th>\n",
       "      <th>TCARBON_EQ</th>\n",
       "      <th>GYPSUM</th>\n",
       "      <th>ELEC_COND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31802</td>\n",
       "      <td>8.937500</td>\n",
       "      <td>37.537500</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.47</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31802</td>\n",
       "      <td>8.937500</td>\n",
       "      <td>37.537500</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>53</td>\n",
       "      <td>22</td>\n",
       "      <td>7.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.46</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>65</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31805</td>\n",
       "      <td>8.945833</td>\n",
       "      <td>37.537500</td>\n",
       "      <td>9</td>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1.44</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31805</td>\n",
       "      <td>8.945833</td>\n",
       "      <td>37.537500</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>F</td>\n",
       "      <td>1.35</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31802</td>\n",
       "      <td>8.912500</td>\n",
       "      <td>37.529167</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>19</td>\n",
       "      <td>9.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.47</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   HWSD2_SMU_ID  longitude   latitude  COARSE  SAND  SILT  CLAY  TEXTURE_USDA  \\\n",
       "0         31802   8.937500  37.537500      11    40    41    19           9.0   \n",
       "1         31802   8.937500  37.537500       9    25    53    22           7.0   \n",
       "2         31805   8.945833  37.537500       9    87     9     4          12.0   \n",
       "3         31805   8.945833  37.537500       5    33    31    36           5.0   \n",
       "4         31802   8.912500  37.529167      11    40    41    19           9.0   \n",
       "\n",
       "  TEXTURE_SOTER  BULK  ...  CEC_SOIL  CEC_CLAY  CEC_EFF   TEB  BSAT  ALUM_SAT  \\\n",
       "0             M  1.47  ...        11        26      6.0   5.0    47        21   \n",
       "1             M  1.46  ...        15        51     14.0  12.0    65        26   \n",
       "2             C  1.44  ...         4        33      3.0   3.0    76         6   \n",
       "3             F  1.35  ...        20        34     15.0  17.0    82         0   \n",
       "4             M  1.47  ...        11        26      6.0   5.0    47        21   \n",
       "\n",
       "   ESP  TCARBON_EQ  GYPSUM  ELEC_COND  \n",
       "0    1         0.0     0.1          0  \n",
       "1    3         0.0     0.1          0  \n",
       "2    2         0.0     0.1          0  \n",
       "3    1         0.0     1.6          1  \n",
       "4    1         0.0     0.1          0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "soil = pd.read_csv(r\"D:\\S3\\data_mining\\projet\\soil_data.csv\")\n",
    "soil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c046f17",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'row'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_2216\\2467814879.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# --- 5. PERFORM THE FINAL MERGE ---\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Use a LEFT JOIN to keep all rows in the climate_fire_df (all your land pixels)\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# and add the soil properties.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m final_combined_df = climate_fire_df.merge(\n\u001b[32m     45\u001b[39m     soil_df_final,\n\u001b[32m     46\u001b[39m     on=[\u001b[33m'row'\u001b[39m, \u001b[33m'col'\u001b[39m],\n\u001b[32m     47\u001b[39m     how=\u001b[33m'left'\u001b[39m\n",
      "\u001b[32mc:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10855\u001b[39m         validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10856\u001b[39m     ) -> DataFrame:\n\u001b[32m  10857\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m  10858\u001b[39m \n\u001b[32m> \u001b[39m\u001b[32m10859\u001b[39m         return merge(\n\u001b[32m  10860\u001b[39m             self,\n\u001b[32m  10861\u001b[39m             right,\n\u001b[32m  10862\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    166\u001b[39m             validate=validate,\n\u001b[32m    167\u001b[39m             copy=copy,\n\u001b[32m    168\u001b[39m         )\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m         op = _MergeOperation(\n\u001b[32m    171\u001b[39m             left_df,\n\u001b[32m    172\u001b[39m             right_df,\n\u001b[32m    173\u001b[39m             how=how,\n",
      "\u001b[32mc:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    790\u001b[39m             self.right_join_keys,\n\u001b[32m    791\u001b[39m             self.join_names,\n\u001b[32m    792\u001b[39m             left_drop,\n\u001b[32m    793\u001b[39m             right_drop,\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m         ) = self._get_merge_keys()\n\u001b[32m    795\u001b[39m \n\u001b[32m    796\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[32m    797\u001b[39m             self.left = self.left._drop_labels_or_levels(left_drop)\n",
      "\u001b[32mc:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1307\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1308\u001b[39m                         \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[32m   1309\u001b[39m                         \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[32m   1310\u001b[39m                         lk = cast(Hashable, lk)\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m                         left_keys.append(left._get_label_or_level_values(lk))\n\u001b[32m   1312\u001b[39m                         join_names.append(lk)\n\u001b[32m   1313\u001b[39m                     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1314\u001b[39m                         \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\serra\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'row'"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import pandas as pd\n",
    "from rasterio.transform import rowcol\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# --- 1. DEFINE FILE PATHS (CRITICAL: UPDATE THESE) ---\n",
    "# Assuming you saved your final climate/fire data here:\n",
    "climate_fire_file = r\"D:\\S3\\rapport data_mining\\newdata\\fire_climate_7km_final.csv\"\n",
    "# **UPDATE THIS PATH** to the location of your soil data CSV\n",
    "soil_file = r\"D:\\S3\\data_mining\\projet\\soil_data.csv\" \n",
    "# This path is needed to get the grid transform\n",
    "tif_folder = r\"D:\\S3\\data_mining\\projet\\clipped_imputed_data2\\\\\" \n",
    "tif_files = sorted(glob.glob(tif_folder + \"*_imputed_local.tif\"))\n",
    "\n",
    "\n",
    "# --- 2. LOAD DATA ---\n",
    "climate_fire_df = pd.read_csv(climate_fire_file)\n",
    "#soil_df = pd.read_csv(soil_file)\n",
    "\n",
    "# Get the Transformation matrix from the first climate TIF file\n",
    "with rasterio.open(tif_files[0]) as src:\n",
    "    transform = src.transform\n",
    "\n",
    "# --- 3. MAP SOIL COORDINATES TO GRID INDICES ---\n",
    "# Calculate 'row' and 'col' for the soil data using the TIF transform\n",
    "rows, cols = rowcol(transform, soil['longitude'], soil['latitude'])\n",
    "soil['row'] = rows\n",
    "soil['col'] = cols\n",
    "\n",
    "# --- 4. PREPARE SOIL DATA FOR MERGE ---\n",
    "# Keep all soil property columns and drop the redundant float coordinates\n",
    "soil_cols_to_keep = [\n",
    "    col for col in soil.columns \n",
    "    if col not in ['longitude', 'latitude']\n",
    "]\n",
    "# Ensure we only have unique grid cells for merging\n",
    "soil_df_final = soil[soil_cols_to_keep].drop_duplicates(subset=['row', 'col'])\n",
    "\n",
    "\n",
    "# --- 5. PERFORM THE FINAL MERGE ---\n",
    "# Use a LEFT JOIN to keep all rows in the climate_fire_df (all your land pixels)\n",
    "# and add the soil properties.\n",
    "final_combined_df = climate_fire_df.merge(\n",
    "    soil_df_final,\n",
    "    on=['row', 'col'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- 6. CLEANUP AND SAVE ---\n",
    "# Check for missing soil data (where a land pixel didn't match a soil polygon)\n",
    "print(f\"Final Combined DataFrame size: {len(final_combined_df)}\")\n",
    "print(f\"Number of land pixels with missing soil data: {final_combined_df['HWSD2_SMU_ID'].isna().sum()}\")\n",
    "\n",
    "# Fill remaining NaN values in soil columns (optional, based on model needs)\n",
    "# You may want to fill soil properties with 0 or the mean/median, depending on the variable.\n",
    "# For now, we'll keep the NaNs or use a simple fill for demonstration:\n",
    "# soil_property_cols = [col for col in final_combined_df.columns if col.upper() in ['COARSESAND', 'SILT', 'CLAY', 'BULK']]\n",
    "# final_combined_df[soil_property_cols] = final_combined_df[soil_property_cols].fillna(0)\n",
    "\n",
    "\n",
    "# Save the final, complete dataset\n",
    "final_combined_df.to_csv(\"final_climate_fire_soil_data.csv\", index=False)\n",
    "\n",
    "final_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba054c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "    ‚ïë                                                                  ‚ïë\n",
      "    ‚ïë   CLIMATE + FIRE + SOIL DATA INTEGRATION PIPELINE               ‚ïë\n",
      "    ‚ïë                                                                  ‚ïë\n",
      "    ‚ïë   Combines 7km climate grid, fire occurrences, and soil data   ‚ïë\n",
      "    ‚ïë   into a single ML-ready dataset                                ‚ïë\n",
      "    ‚ïë                                                                  ‚ïë\n",
      "    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "    \n",
      "\n",
      "üìã CONFIGURATION:\n",
      "   Input files:\n",
      "     - Climate/Fire: D:\\S3\\rapport data_mining\\newdata\\fire_climate_7km_final.csv\n",
      "     - Soil: D:\\S3\\data_mining\\projet\\soil_data.csv\n",
      "     - TIF folder: D:\\S3\\data_mining\\projet\\clipped_imputed_data2\\\\\n",
      "\n",
      "   Output file: final_climate_fire_soil_7km.csv\n",
      "\n",
      "   Options:\n",
      "     - Fill missing soil: True\n",
      "     - Drop rows without soil: False\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "  CLIMATE + FIRE + SOIL DATA INTEGRATION\n",
      "======================================================================\n",
      "\n",
      "üìÇ STEP 1: LOADING DATA\n",
      "----------------------------------------------------------------------\n",
      "Loading climate/fire data from: D:\\S3\\rapport data_mining\\newdata\\fire_climate_7km_final.csv\n",
      "  ‚úÖ Loaded 65,660 rows √ó 39 columns\n",
      "\n",
      "Loading soil data from: D:\\S3\\data_mining\\projet\\soil_data.csv\n",
      "  ‚úÖ Loaded 7,113,536 rows √ó 25 columns\n",
      "\n",
      "Loading transform matrix from: D:\\S3\\data_mining\\projet\\clipped_imputed_data2\\wc2.1_cruts4.09_5m_prec_2024-01_imputed_local.tif\n",
      "  ‚úÖ Transform matrix loaded\n",
      "\n",
      "üó∫Ô∏è  STEP 2: CALCULATING GRID INDICES FOR CLIMATE DATA\n",
      "----------------------------------------------------------------------\n",
      "Converting (longitude, latitude) to (row, col) for climate data...\n",
      "  ‚úÖ Added 'row' and 'col' columns to climate data\n",
      "     Row range: 0 to 219\n",
      "     Col range: 0 to 247\n",
      "\n",
      "üå± STEP 3: CALCULATING GRID INDICES FOR SOIL DATA\n",
      "----------------------------------------------------------------------\n",
      "Converting (longitude, latitude) to (row, col) for soil data...\n",
      "  ‚úÖ Added 'row' and 'col' columns to soil data\n",
      "     Row range: -3 to 220\n",
      "     Col range: -1 to 247\n",
      "\n",
      "üîß STEP 4: PREPARING SOIL DATA FOR MERGE\n",
      "----------------------------------------------------------------------\n",
      "Keeping 25 soil columns\n",
      "  ‚úÖ Removed 7,080,060 duplicate grid cells\n",
      "  ‚úÖ Unique soil grid cells: 33,476\n",
      "  ‚úÖ Soil properties to merge: 23\n",
      "     HWSD2_SMU_ID, COARSE, SAND, SILT, CLAY, TEXTURE_USDA, TEXTURE_SOTER, BULK, REF_BULK, ORG_CARBON...\n",
      "\n",
      "üîó STEP 5: MERGING DATASETS\n",
      "----------------------------------------------------------------------\n",
      "Performing LEFT JOIN on (row, col)...\n",
      "  Strategy: Keep all climate points, add soil where available\n",
      "  ‚úÖ Merge complete!\n",
      "     Input rows: 65,660\n",
      "     Output rows: 65,660\n",
      "     Columns: 41 ‚Üí 64\n",
      "\n",
      "üìä STEP 6: ANALYZING DATA COVERAGE\n",
      "----------------------------------------------------------------------\n",
      "Soil Data Coverage:\n",
      "  ‚úÖ Points WITH soil data:    58,108 (88.5%)\n",
      "  ‚ùå Points WITHOUT soil data: 7,552 (11.5%)\n",
      "\n",
      "Missing values by soil property:\n",
      "  HWSD2_SMU_ID                  : 7,552 missing (11.5%)\n",
      "  COARSE                        : 7,552 missing (11.5%)\n",
      "  SAND                          : 7,552 missing (11.5%)\n",
      "  SILT                          : 7,552 missing (11.5%)\n",
      "  CLAY                          : 7,552 missing (11.5%)\n",
      "  TEXTURE_USDA                  : 21,223 missing (32.3%)\n",
      "  TEXTURE_SOTER                 : 7,552 missing (11.5%)\n",
      "  BULK                          : 7,552 missing (11.5%)\n",
      "  REF_BULK                      : 7,552 missing (11.5%)\n",
      "  ORG_CARBON                    : 7,552 missing (11.5%)\n",
      "  ... and 13 more soil properties\n",
      "\n",
      "Column Breakdown:\n",
      "  Climate variables: 36\n",
      "  Soil properties: 23\n",
      "  Other (coords, indices, fire): 5\n",
      "\n",
      "Fire Distribution:\n",
      "  üî• Fire points: 3,600 (5.48%)\n",
      "  ‚≠ï Non-fire points: 62,060 (94.52%)\n",
      "\n",
      "üîß STEP 7: HANDLING MISSING VALUES\n",
      "----------------------------------------------------------------------\n",
      "Option: FILL missing soil values with median\n",
      "  Filled 'HWSD2_SMU_ID' with median: 1642.00\n",
      "  Filled 'COARSE' with median: 12.00\n",
      "  Filled 'SAND' with median: 49.00\n",
      "  Filled 'SILT' with median: 27.00\n",
      "  Filled 'CLAY' with median: 16.00\n",
      "  Filled 'TEXTURE_USDA' with median: 9.00\n",
      "  Filled 'TEXTURE_SOTER' with mode: M\n",
      "  Filled 'BULK' with median: 1.43\n",
      "  Filled 'REF_BULK' with median: 1.65\n",
      "  Filled 'ORG_CARBON' with median: 0.69\n",
      "  Filled 'PH_WATER' with median: 7.80\n",
      "  Filled 'TOTAL_N' with median: 0.73\n",
      "  Filled 'CN_RATIO' with median: 9.00\n",
      "  Filled 'CEC_SOIL' with median: 13.00\n",
      "  Filled 'CEC_CLAY' with median: 52.00\n",
      "  Filled 'CEC_EFF' with median: 30.00\n",
      "  Filled 'TEB' with median: 30.00\n",
      "  Filled 'BSAT' with median: 97.00\n",
      "  Filled 'ALUM_SAT' with median: 0.00\n",
      "  Filled 'ESP' with median: 3.00\n",
      "  Filled 'TCARBON_EQ' with median: 8.00\n",
      "  Filled 'GYPSUM' with median: 0.30\n",
      "  Filled 'ELEC_COND' with median: 1.00\n",
      "  ‚úÖ Filled 23 soil columns\n",
      "\n",
      "‚úÖ STEP 8: FINAL VALIDATION\n",
      "----------------------------------------------------------------------\n",
      "‚úÖ No missing values - dataset is complete!\n",
      "\n",
      "Data Types:\n",
      "  Numeric columns: 63\n",
      "  Object columns: 1\n",
      "\n",
      "Memory Usage: 34.2 MB\n",
      "\n",
      "üíæ STEP 9: SAVING FINAL DATASET\n",
      "----------------------------------------------------------------------\n",
      "Saving to: final_climate_fire_soil_7km.csv\n",
      "  ‚úÖ File saved successfully!\n",
      "     Rows: 65,660\n",
      "     Columns: 64\n",
      "     File size: ~34.7 MB\n",
      "\n",
      "======================================================================\n",
      "üéâ PROCESSING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "üìã FINAL DATASET SUMMARY:\n",
      "   Total grid points: 65,660\n",
      "   Total features: 64\n",
      "   Fire points: 3,600 (5.48%)\n",
      "\n",
      "üìä FEATURE BREAKDOWN:\n",
      "   Climate variables: 36\n",
      "   Soil properties: 23\n",
      "   Geographic: 4 (lon, lat, row, col)\n",
      "   Target: 1 (is_fire)\n",
      "\n",
      "üíæ OUTPUT FILE: final_climate_fire_soil_7km.csv\n",
      "\n",
      "‚ú® Your dataset is ready for machine learning!\n",
      "\n",
      "======================================================================\n",
      "üìã DATASET PREVIEW\n",
      "======================================================================\n",
      "\n",
      "First 5 rows:\n",
      "   longitude   latitude   prec_jan   prec_feb   prec_mar   prec_apr   prec_may   prec_jun  prec_jul  prec_aug   prec_sep   prec_oct  prec_nov    prec_dec   tmax_jan   tmax_feb   tmax_mar   tmax_apr   tmax_may   tmax_jun   tmax_jul   tmax_aug   tmax_sep   tmax_oct   tmax_nov   tmax_dec  tmin_jan  tmin_feb   tmin_mar   tmin_apr   tmin_may   tmin_jun   tmin_jul   tmin_aug   tmin_sep   tmin_oct   tmin_nov  tmin_dec  is_fire  row  col  HWSD2_SMU_ID  COARSE  SAND  SILT  CLAY  TEXTURE_USDA TEXTURE_SOTER  BULK  REF_BULK  ORG_CARBON  PH_WATER  TOTAL_N  CN_RATIO  CEC_SOIL  CEC_CLAY  CEC_EFF   TEB  BSAT  ALUM_SAT  ESP  TCARBON_EQ  GYPSUM  ELEC_COND\n",
      "0   3.436290  37.301724  76.186775  150.25905  33.161297  30.770489  18.069036  12.214680  0.669839  5.152906  47.169990  56.678230  76.63838   99.480160  17.591934  17.683868  20.091934  22.091934  25.183868  28.500000  32.500000  32.500000  28.841934  26.750000  22.433868  16.000000  8.250000  8.250000  10.091934  11.683868  15.000000  18.091934  21.183868  22.000000  18.341934  16.841934  13.250000  6.933868        0    0  145        1642.0    12.0  49.0  27.0  16.0           9.0             M  1.43  1.651545       0.695       7.8     0.73       9.0      13.0      52.0     30.0  30.0  97.0       0.0  3.0         8.0     0.3        1.0\n",
      "1   3.499490  37.301724  76.784424  149.66905  33.240920  30.732008  18.085820  12.146191  0.625306  5.149389  47.514935  56.663334  77.78015  100.125590  17.604422  17.708843  20.022108  22.022108  25.208843  28.582314  32.541157  32.541157  28.895578  26.708843  22.458843  16.000000  8.291157  8.291157  10.186735  11.708843  15.000000  18.145578  21.332314  22.000000  18.395578  16.854422  13.291157  7.000000        0    0  145        1642.0    12.0  49.0  27.0  16.0           9.0             M  1.43  1.651545       0.695       7.8     0.73       9.0      13.0      52.0     30.0  30.0  97.0       0.0  3.0         8.0     0.3        1.0\n",
      "2   3.562691  37.301724  78.065575  150.86105  33.845560  31.252170  18.496216  12.244916  0.584232  5.281996  47.859642  57.129864  79.62057  101.383736  17.483467  17.577312  19.811544  21.811544  25.077312  28.608849  32.546540  32.562310  28.843080  26.577312  22.311544  15.921158  8.312308  8.312308  10.202695  11.640387  14.968463  18.140385  21.421923  21.984232  18.406155  16.796541  13.280772  6.952695        0    0  146        1642.0    12.0  49.0  27.0  16.0           9.0             M  1.43  1.651545       0.695       7.8     0.73       9.0      13.0      52.0     30.0  30.0  97.0       0.0  3.0         8.0     0.3        1.0\n",
      "3   3.625892  37.301724  80.098495  153.96217  34.947132  32.472347  19.301392  12.625588  0.536992  5.526338  48.457787  58.205757  82.26333  103.217290  17.186563  17.311830  19.499464  21.497860  24.811830  28.436563  32.436560  32.499466  28.623663  26.310760  21.998394  15.686029  8.250000  8.250000  10.062902  11.562366  14.874197  18.063437  21.438170  21.937634  18.375267  16.687100  13.124732  6.812901        0    0  147        1642.0    12.0  49.0  27.0  16.0           9.0             M  1.43  1.651545       0.695       7.8     0.73       9.0      13.0      52.0     30.0  30.0  97.0       0.0  3.0         8.0     0.3        1.0\n",
      "4   3.689093  37.301724  80.877760  154.38214  35.186985  32.727364  19.399984  12.667301  0.500967  5.621139  48.566807  58.170680  83.20755  103.556680  17.120203  17.264431  19.461544  21.346176  24.764431  28.370203  32.370200  32.461544  28.528860  26.187520  21.884634  15.581747  8.250000  8.250000  10.091342  11.552886  14.817317  18.129797  21.485569  21.947115  18.394228  16.658657  13.105772  6.841342        0    0  148        1642.0    12.0  49.0  27.0  16.0           9.0             M  1.43  1.651545       0.695       7.8     0.73       9.0      13.0      52.0     30.0  30.0  97.0       0.0  3.0         8.0     0.3        1.0\n",
      "\n",
      "\n",
      "All columns (64):\n",
      "   1. longitude\n",
      "   2. latitude\n",
      "   3. prec_jan\n",
      "   4. prec_feb\n",
      "   5. prec_mar\n",
      "   6. prec_apr\n",
      "   7. prec_may\n",
      "   8. prec_jun\n",
      "   9. prec_jul\n",
      "  10. prec_aug\n",
      "  11. prec_sep\n",
      "  12. prec_oct\n",
      "  13. prec_nov\n",
      "  14. prec_dec\n",
      "  15. tmax_jan\n",
      "  16. tmax_feb\n",
      "  17. tmax_mar\n",
      "  18. tmax_apr\n",
      "  19. tmax_may\n",
      "  20. tmax_jun\n",
      "  21. tmax_jul\n",
      "  22. tmax_aug\n",
      "  23. tmax_sep\n",
      "  24. tmax_oct\n",
      "  25. tmax_nov\n",
      "  26. tmax_dec\n",
      "  27. tmin_jan\n",
      "  28. tmin_feb\n",
      "  29. tmin_mar\n",
      "  30. tmin_apr\n",
      "  31. tmin_may\n",
      "  32. tmin_jun\n",
      "  33. tmin_jul\n",
      "  34. tmin_aug\n",
      "  35. tmin_sep\n",
      "  36. tmin_oct\n",
      "  37. tmin_nov\n",
      "  38. tmin_dec\n",
      "  39. is_fire\n",
      "  40. row\n",
      "  41. col\n",
      "  42. HWSD2_SMU_ID\n",
      "  43. COARSE\n",
      "  44. SAND\n",
      "  45. SILT\n",
      "  46. CLAY\n",
      "  47. TEXTURE_USDA\n",
      "  48. TEXTURE_SOTER\n",
      "  49. BULK\n",
      "  50. REF_BULK\n",
      "  51. ORG_CARBON\n",
      "  52. PH_WATER\n",
      "  53. TOTAL_N\n",
      "  54. CN_RATIO\n",
      "  55. CEC_SOIL\n",
      "  56. CEC_CLAY\n",
      "  57. CEC_EFF\n",
      "  58. TEB\n",
      "  59. BSAT\n",
      "  60. ALUM_SAT\n",
      "  61. ESP\n",
      "  62. TCARBON_EQ\n",
      "  63. GYPSUM\n",
      "  64. ELEC_COND\n",
      "\n",
      "\n",
      "Basic Statistics:\n",
      "          longitude      latitude      prec_jan      prec_feb      prec_mar      prec_apr      prec_may      prec_jun      prec_jul      prec_aug      prec_sep      prec_oct      prec_nov      prec_dec      tmax_jan      tmax_feb      tmax_mar      tmax_apr      tmax_may      tmax_jun      tmax_jul      tmax_aug      tmax_sep      tmax_oct      tmax_nov      tmax_dec      tmin_jan      tmin_feb      tmin_mar      tmin_apr      tmin_may      tmin_jun      tmin_jul      tmin_aug      tmin_sep      tmin_oct      tmin_nov      tmin_dec       is_fire           row           col  HWSD2_SMU_ID        COARSE          SAND          SILT          CLAY  TEXTURE_USDA          BULK      REF_BULK    ORG_CARBON      PH_WATER       TOTAL_N      CN_RATIO      CEC_SOIL      CEC_CLAY       CEC_EFF           TEB          BSAT      ALUM_SAT           ESP    TCARBON_EQ        GYPSUM     ELEC_COND\n",
      "count  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000  65660.000000\n",
      "mean       3.136178     28.611170      5.168262     10.510042      5.013345      6.733857      3.935983      2.241773      1.144516      4.437044     10.930939      7.370416      5.569721      8.625769     20.371380     22.895618     27.105397     31.373390     35.619874     39.600282     41.701155     40.467107     36.443269     32.420962     26.197800     20.350762      5.901625      8.561060     11.861754     16.382092     21.146491     24.555165     26.703019     26.289912     23.141439     18.802916     12.464182      6.426446      0.054828    104.162885    141.137374   3078.358163      8.214529     40.709184     22.374794     12.808346      9.415047      0.342323      1.654603     -0.222089      5.412158     -0.182106      7.070835      9.050853     44.712961     25.715519     23.380810     71.562656     -0.766372      2.357128      6.700956      0.897679      0.252680\n",
      "std        4.863218      4.633707     12.496833     26.260691      7.582421     11.089423      6.182543      3.071894      1.782078      5.652947     13.266087     11.216985     10.246467     18.764053      3.314456      3.967670      4.569262      5.161562      4.748453      4.206917      3.761247      3.644874      3.939517      4.012495      3.448145      4.118693      2.197060      2.359994      2.913456      3.768119      3.945770      3.427430      3.013122      2.909249      3.310592      2.998107      2.159907      2.330273      0.227646     55.609298     58.362259   7317.542361      7.615605     24.935317     14.806969      9.653386      1.480657      2.138010      0.082475      1.862191      4.740348      1.878910      5.759719      7.526230     28.019379     20.003835     20.800903     40.609373      1.708408      6.810685      6.327273      6.204277      2.648714\n",
      "min       -8.635066     19.031609      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      7.363974      8.278327     12.559521     15.679189     20.046030     26.015821     29.275331     28.412870     22.827223     18.460382     13.262009      6.131676     -1.360092      0.162870      2.176362      4.519047      7.282538     12.189596     15.282538     14.282538     11.077224      8.779711      4.143922     -1.546069      0.000000      0.000000      0.000000     36.000000     -9.000000     -9.000000     -9.000000     -9.000000      3.000000     -9.000000      1.200000     -9.000000     -9.000000     -9.000000     -9.000000     -9.000000     -9.000000     -9.000000     -9.000000     -9.000000     -9.000000     -9.000000     -9.000000     -9.000000     -9.000000\n",
      "25%       -0.418960     24.910920      0.700000      0.800000      0.900000      0.000000      0.716171      0.500000      0.000000      1.000000      1.640022      1.000000      0.998034      0.700000     18.594946     20.849111     24.945981     29.000000     33.715221     37.906299     39.000000     37.664296     34.685969     30.040169     24.479679     18.000000      4.000000      7.000000     10.000000     14.559583     19.605638     23.031523     25.000000     24.528482     21.888649     17.000000     11.000000      5.000000      0.000000     59.000000     98.000000    340.000000      3.000000     36.000000     22.000000     12.000000      9.000000      1.350000      1.650000      0.588000      7.400000      0.580000      9.000000      6.000000     35.000000     25.000000     10.000000     64.000000      0.000000      2.000000      5.800000      0.200000      1.000000\n",
      "50%        3.499490     28.514368      1.316526      1.863146      2.123513      1.704138      1.782118      1.000000      0.708892      2.079969      4.902638      1.900000      2.270735      2.418486     20.215072     23.179620     28.000000     32.336548     37.000000     41.000000     42.802490     41.129963     37.058308     33.080067     27.000000     20.847858      6.000000      8.636727     12.000000     17.000000     22.000000     25.780143     27.000000     26.954479     24.000000     19.000000     12.482641      6.231095      0.000000    105.000000    145.000000   1642.000000     12.000000     49.000000     27.000000     16.000000      9.000000      1.430000      1.651545      0.695000      7.800000      0.730000      9.000000     13.000000     52.000000     30.000000     30.000000     97.000000      0.000000      3.000000      8.000000      0.300000      1.000000\n",
      "75%        7.101937     32.370690      3.298627      4.879767      4.420535      8.630873      3.891379      2.645440      1.190517      5.450921     15.919927      8.728802      5.285302      8.219336     22.958587     26.000000     30.488814     35.325104     39.117905     43.000000     45.000000     43.732758     39.000000     35.024132     29.000000     23.405172      7.907232     10.045898     14.000000     19.000000     24.000000     27.000000     29.000000     28.976937     25.000000     20.679321     14.000000      8.000000      0.000000    149.000000    189.000000   1819.000000     12.000000     57.000000     33.000000     18.000000     11.000000      1.450000      1.680000      0.711000      8.200000      0.800000      9.000000     14.000000     67.000000     37.000000     38.000000    100.000000      0.000000      3.000000     11.300000      0.600000      1.000000\n",
      "max       11.968400     37.301724    134.337600    254.594700     47.668762     90.065315     41.016483     20.786211     24.649520     39.348470     78.932630     77.050520     91.747770    209.671720     28.000000     30.000000     36.307370     40.997100     42.387930     45.993217     47.984650     46.597023     43.219540     39.975758     32.086586     29.000000     11.000000     14.000000     19.000000     24.000000     28.199160     30.000000     31.988533     31.000000     29.000000     25.187460     17.000000     12.000000      1.000000    219.000000    247.000000  32050.000000     46.000000     90.000000     46.000000     55.000000     12.000000      1.760000      2.030000      5.923000      8.600000      3.690000     15.000000     41.000000     83.000000    143.000000    143.000000    100.000000     40.000000     67.000000     27.900000     57.599998     32.000000\n",
      "\n",
      "======================================================================\n",
      "SUCCESS! üéâ\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Complete Climate + Fire + Soil Data Integration\n",
    "================================================\n",
    "This script merges climate data (7km grid), fire occurrences, and soil properties\n",
    "into a single ML-ready dataset.\n",
    "\n",
    "Author: Climate Analysis Pipeline\n",
    "Date: 2025\n",
    "\n",
    "deleate itttttttttttttttt\n",
    "\"\"\"\n",
    "\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "from rasterio.transform import rowcol\n",
    "import numpy as np\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - UPDATE THESE PATHS\n",
    "# ============================================================================\n",
    "\n",
    "# Input files\n",
    "CLIMATE_FIRE_FILE = r\"D:\\S3\\rapport data_mining\\newdata\\fire_climate_7km_final.csv\"\n",
    "SOIL_FILE = r\"D:\\S3\\data_mining\\projet\\soil_data.csv\"\n",
    "TIF_FOLDER = r\"D:\\S3\\data_mining\\projet\\clipped_imputed_data2\\\\\"\n",
    "\n",
    "# Output file\n",
    "OUTPUT_FILE = \"final_climate_fire_soil_7km.csv\"\n",
    "\n",
    "# Options\n",
    "FILL_MISSING_SOIL = True  # Fill missing soil values with median?\n",
    "DROP_NO_SOIL = False      # Drop rows without soil data? (Not recommended)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN PROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to merge climate, fire, and soil data.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"  CLIMATE + FIRE + SOIL DATA INTEGRATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # STEP 1: LOAD DATA\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\nüìÇ STEP 1: LOADING DATA\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Load climate + fire data\n",
    "    print(f\"Loading climate/fire data from: {CLIMATE_FIRE_FILE}\")\n",
    "    climate_fire_df = pd.read_csv(CLIMATE_FIRE_FILE)\n",
    "    print(f\"  ‚úÖ Loaded {len(climate_fire_df):,} rows √ó {len(climate_fire_df.columns)} columns\")\n",
    "    \n",
    "    # Load soil data\n",
    "    print(f\"\\nLoading soil data from: {SOIL_FILE}\")\n",
    "    soil_df = pd.read_csv(SOIL_FILE)\n",
    "    print(f\"  ‚úÖ Loaded {len(soil_df):,} rows √ó {len(soil_df.columns)} columns\")\n",
    "    \n",
    "    # Get TIF files for transform matrix\n",
    "    tif_files = sorted(glob.glob(TIF_FOLDER + \"*.tif\"))\n",
    "    if len(tif_files) == 0:\n",
    "        raise ValueError(f\"‚ùå No TIF files found in {TIF_FOLDER}\")\n",
    "    \n",
    "    print(f\"\\nLoading transform matrix from: {tif_files[0]}\")\n",
    "    with rasterio.open(tif_files[0]) as src:\n",
    "        transform = src.transform\n",
    "    print(f\"  ‚úÖ Transform matrix loaded\")\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # STEP 2: CALCULATE GRID INDICES FOR CLIMATE DATA\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\nüó∫Ô∏è  STEP 2: CALCULATING GRID INDICES FOR CLIMATE DATA\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    print(\"Converting (longitude, latitude) to (row, col) for climate data...\")\n",
    "    climate_rows, climate_cols = rowcol(\n",
    "        transform, \n",
    "        climate_fire_df['longitude'].values, \n",
    "        climate_fire_df['latitude'].values\n",
    "    )\n",
    "    \n",
    "    climate_fire_df['row'] = climate_rows\n",
    "    climate_fire_df['col'] = climate_cols\n",
    "    \n",
    "    print(f\"  ‚úÖ Added 'row' and 'col' columns to climate data\")\n",
    "    print(f\"     Row range: {climate_fire_df['row'].min()} to {climate_fire_df['row'].max()}\")\n",
    "    print(f\"     Col range: {climate_fire_df['col'].min()} to {climate_fire_df['col'].max()}\")\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # STEP 3: CALCULATE GRID INDICES FOR SOIL DATA\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\nüå± STEP 3: CALCULATING GRID INDICES FOR SOIL DATA\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    print(\"Converting (longitude, latitude) to (row, col) for soil data...\")\n",
    "    soil_rows, soil_cols = rowcol(\n",
    "        transform, \n",
    "        soil_df['longitude'].values, \n",
    "        soil_df['latitude'].values\n",
    "    )\n",
    "    \n",
    "    soil_df['row'] = soil_rows\n",
    "    soil_df['col'] = soil_cols\n",
    "    \n",
    "    print(f\"  ‚úÖ Added 'row' and 'col' columns to soil data\")\n",
    "    print(f\"     Row range: {soil_df['row'].min()} to {soil_df['row'].max()}\")\n",
    "    print(f\"     Col range: {soil_df['col'].min()} to {soil_df['col'].max()}\")\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # STEP 4: PREPARE SOIL DATA FOR MERGE\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\nüîß STEP 4: PREPARING SOIL DATA FOR MERGE\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Get all soil columns except the float coordinates\n",
    "    soil_cols_to_keep = [\n",
    "        col for col in soil_df.columns \n",
    "        if col not in ['longitude', 'latitude']\n",
    "    ]\n",
    "    \n",
    "    print(f\"Keeping {len(soil_cols_to_keep)} soil columns\")\n",
    "    \n",
    "    # Remove duplicate grid cells (keep first occurrence)\n",
    "    soil_df_unique = soil_df[soil_cols_to_keep].drop_duplicates(subset=['row', 'col'])\n",
    "    \n",
    "    duplicates_removed = len(soil_df) - len(soil_df_unique)\n",
    "    print(f\"  ‚úÖ Removed {duplicates_removed:,} duplicate grid cells\")\n",
    "    print(f\"  ‚úÖ Unique soil grid cells: {len(soil_df_unique):,}\")\n",
    "    \n",
    "    # Identify soil property columns\n",
    "    soil_property_cols = [\n",
    "        col for col in soil_df_unique.columns \n",
    "        if col not in ['row', 'col'] and not col.startswith('Unnamed')\n",
    "    ]\n",
    "    print(f\"  ‚úÖ Soil properties to merge: {len(soil_property_cols)}\")\n",
    "    if len(soil_property_cols) <= 10:\n",
    "        print(f\"     {', '.join(soil_property_cols)}\")\n",
    "    else:\n",
    "        print(f\"     {', '.join(soil_property_cols[:10])}...\")\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # STEP 5: MERGE CLIMATE + FIRE + SOIL\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\nüîó STEP 5: MERGING DATASETS\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    print(\"Performing LEFT JOIN on (row, col)...\")\n",
    "    print(\"  Strategy: Keep all climate points, add soil where available\")\n",
    "    \n",
    "    final_df = climate_fire_df.merge(\n",
    "        soil_df_unique,\n",
    "        on=['row', 'col'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(f\"  ‚úÖ Merge complete!\")\n",
    "    print(f\"     Input rows: {len(climate_fire_df):,}\")\n",
    "    print(f\"     Output rows: {len(final_df):,}\")\n",
    "    print(f\"     Columns: {len(climate_fire_df.columns)} ‚Üí {len(final_df.columns)}\")\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # STEP 6: ANALYZE DATA COVERAGE\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\nüìä STEP 6: ANALYZING DATA COVERAGE\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Check soil data coverage\n",
    "    if soil_property_cols:\n",
    "        first_soil_col = soil_property_cols[0]\n",
    "        missing_soil = final_df[first_soil_col].isna().sum()\n",
    "        has_soil = len(final_df) - missing_soil\n",
    "        \n",
    "        print(f\"Soil Data Coverage:\")\n",
    "        print(f\"  ‚úÖ Points WITH soil data:    {has_soil:,} ({100*has_soil/len(final_df):.1f}%)\")\n",
    "        print(f\"  ‚ùå Points WITHOUT soil data: {missing_soil:,} ({100*missing_soil/len(final_df):.1f}%)\")\n",
    "        \n",
    "        # Check missing values per soil column\n",
    "        print(f\"\\nMissing values by soil property:\")\n",
    "        for col in soil_property_cols[:10]:  # Show first 10\n",
    "            missing = final_df[col].isna().sum()\n",
    "            print(f\"  {col:30s}: {missing:,} missing ({100*missing/len(final_df):.1f}%)\")\n",
    "        \n",
    "        if len(soil_property_cols) > 10:\n",
    "            print(f\"  ... and {len(soil_property_cols) - 10} more soil properties\")\n",
    "    \n",
    "    # Column breakdown\n",
    "    climate_cols = [c for c in final_df.columns if any(x in c for x in ['tmin', 'tmax', 'prec', 'tavg'])]\n",
    "    \n",
    "    print(f\"\\nColumn Breakdown:\")\n",
    "    print(f\"  Climate variables: {len(climate_cols)}\")\n",
    "    print(f\"  Soil properties: {len(soil_property_cols)}\")\n",
    "    print(f\"  Other (coords, indices, fire): {len(final_df.columns) - len(climate_cols) - len(soil_property_cols)}\")\n",
    "    \n",
    "    # Fire distribution\n",
    "    if 'is_fire' in final_df.columns:\n",
    "        fire_count = (final_df['is_fire'] == 1).sum()\n",
    "        print(f\"\\nFire Distribution:\")\n",
    "        print(f\"  üî• Fire points: {fire_count:,} ({100*fire_count/len(final_df):.2f}%)\")\n",
    "        print(f\"  ‚≠ï Non-fire points: {len(final_df) - fire_count:,} ({100*(len(final_df)-fire_count)/len(final_df):.2f}%)\")\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # STEP 7: HANDLE MISSING VALUES\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\nüîß STEP 7: HANDLING MISSING VALUES\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    if DROP_NO_SOIL:\n",
    "        print(\"Option: DROP rows without soil data\")\n",
    "        before = len(final_df)\n",
    "        final_df = final_df.dropna(subset=soil_property_cols)\n",
    "        after = len(final_df)\n",
    "        print(f\"  ‚úÖ Dropped {before - after:,} rows\")\n",
    "        print(f\"  ‚úÖ Remaining: {after:,} rows\")\n",
    "        \n",
    "    elif FILL_MISSING_SOIL:\n",
    "        print(\"Option: FILL missing soil values with median\")\n",
    "        filled_count = 0\n",
    "        \n",
    "        for col in soil_property_cols:\n",
    "            if final_df[col].isna().any():\n",
    "                # Check if column is numeric\n",
    "                if pd.api.types.is_numeric_dtype(final_df[col]):\n",
    "                    median_val = final_df[col].median()\n",
    "                    final_df[col].fillna(median_val, inplace=True)\n",
    "                    filled_count += 1\n",
    "                    print(f\"  Filled '{col}' with median: {median_val:.2f}\")\n",
    "                else:\n",
    "                    # For categorical, fill with mode\n",
    "                    mode_val = final_df[col].mode()[0] if not final_df[col].mode().empty else 'Unknown'\n",
    "                    final_df[col].fillna(mode_val, inplace=True)\n",
    "                    filled_count += 1\n",
    "                    print(f\"  Filled '{col}' with mode: {mode_val}\")\n",
    "        \n",
    "        print(f\"  ‚úÖ Filled {filled_count} soil columns\")\n",
    "    else:\n",
    "        print(\"Option: KEEP missing values as NaN\")\n",
    "        print(\"  ‚ö†Ô∏è  Warning: Some ML algorithms may not handle NaN values\")\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # STEP 8: FINAL VALIDATION\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\n‚úÖ STEP 8: FINAL VALIDATION\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Check for any remaining NaN values\n",
    "    total_nan = final_df.isna().sum().sum()\n",
    "    if total_nan > 0:\n",
    "        print(f\"‚ö†Ô∏è  Warning: {total_nan:,} NaN values remain in dataset\")\n",
    "        cols_with_nan = final_df.columns[final_df.isna().any()].tolist()\n",
    "        print(f\"   Columns with NaN: {', '.join(cols_with_nan[:5])}...\")\n",
    "    else:\n",
    "        print(f\"‚úÖ No missing values - dataset is complete!\")\n",
    "    \n",
    "    # Check data types\n",
    "    print(f\"\\nData Types:\")\n",
    "    print(f\"  Numeric columns: {len(final_df.select_dtypes(include=[np.number]).columns)}\")\n",
    "    print(f\"  Object columns: {len(final_df.select_dtypes(include=['object']).columns)}\")\n",
    "    \n",
    "    # Memory usage\n",
    "    memory_mb = final_df.memory_usage(deep=True).sum() / 1024**2\n",
    "    print(f\"\\nMemory Usage: {memory_mb:.1f} MB\")\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # STEP 9: SAVE FINAL DATASET\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\nüíæ STEP 9: SAVING FINAL DATASET\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    print(f\"Saving to: {OUTPUT_FILE}\")\n",
    "    final_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    \n",
    "    file_size_mb = pd.read_csv(OUTPUT_FILE).memory_usage(deep=True).sum() / 1024**2\n",
    "    print(f\"  ‚úÖ File saved successfully!\")\n",
    "    print(f\"     Rows: {len(final_df):,}\")\n",
    "    print(f\"     Columns: {len(final_df.columns)}\")\n",
    "    print(f\"     File size: ~{file_size_mb:.1f} MB\")\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # FINAL SUMMARY\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üéâ PROCESSING COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nüìã FINAL DATASET SUMMARY:\")\n",
    "    print(f\"   Total grid points: {len(final_df):,}\")\n",
    "    print(f\"   Total features: {len(final_df.columns)}\")\n",
    "    \n",
    "    if 'is_fire' in final_df.columns:\n",
    "        fire_count = (final_df['is_fire'] == 1).sum()\n",
    "        print(f\"   Fire points: {fire_count:,} ({100*fire_count/len(final_df):.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nüìä FEATURE BREAKDOWN:\")\n",
    "    print(f\"   Climate variables: {len(climate_cols)}\")\n",
    "    print(f\"   Soil properties: {len(soil_property_cols)}\")\n",
    "    print(f\"   Geographic: 4 (lon, lat, row, col)\")\n",
    "    print(f\"   Target: 1 (is_fire)\")\n",
    "    \n",
    "    print(f\"\\nüíæ OUTPUT FILE: {OUTPUT_FILE}\")\n",
    "    print(f\"\\n‚ú® Your dataset is ready for machine learning!\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PREVIEW FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def preview_dataset(df, n_rows=5):\n",
    "    \"\"\"\n",
    "    Display a preview of the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìã DATASET PREVIEW\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nFirst {n_rows} rows:\")\n",
    "    print(df.head(n_rows).to_string())\n",
    "    \n",
    "    print(f\"\\n\\nAll columns ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\n\\nBasic Statistics:\")\n",
    "    print(df.describe().to_string())\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ENTRY POINT\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\"\"\n",
    "    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "    ‚ïë                                                                  ‚ïë\n",
    "    ‚ïë   CLIMATE + FIRE + SOIL DATA INTEGRATION PIPELINE               ‚ïë\n",
    "    ‚ïë                                                                  ‚ïë\n",
    "    ‚ïë   Combines 7km climate grid, fire occurrences, and soil data   ‚ïë\n",
    "    ‚ïë   into a single ML-ready dataset                                ‚ïë\n",
    "    ‚ïë                                                                  ‚ïë\n",
    "    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "    \"\"\")\n",
    "    \n",
    "    print(f\"\\nüìã CONFIGURATION:\")\n",
    "    print(f\"   Input files:\")\n",
    "    print(f\"     - Climate/Fire: {CLIMATE_FIRE_FILE}\")\n",
    "    print(f\"     - Soil: {SOIL_FILE}\")\n",
    "    print(f\"     - TIF folder: {TIF_FOLDER}\")\n",
    "    print(f\"\\n   Output file: {OUTPUT_FILE}\")\n",
    "    print(f\"\\n   Options:\")\n",
    "    print(f\"     - Fill missing soil: {FILL_MISSING_SOIL}\")\n",
    "    print(f\"     - Drop rows without soil: {DROP_NO_SOIL}\")\n",
    "    print(f\"\\n{'='*70}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Run main processing\n",
    "        final_df = main()\n",
    "        \n",
    "        # Show preview\n",
    "        preview_dataset(final_df, n_rows=5)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"SUCCESS! üéâ\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ERROR: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"\\nüí° TIP: Check that all file paths are correct and files exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7407ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>tmin_2024_1</th>\n",
       "      <th>tmin_2024_2</th>\n",
       "      <th>tmin_2024_3</th>\n",
       "      <th>tmin_2024_4</th>\n",
       "      <th>tmin_2024_5</th>\n",
       "      <th>tmin_2024_6</th>\n",
       "      <th>...</th>\n",
       "      <th>CEC_SOIL</th>\n",
       "      <th>CEC_CLAY</th>\n",
       "      <th>CEC_EFF</th>\n",
       "      <th>TEB</th>\n",
       "      <th>BSAT</th>\n",
       "      <th>ALUM_SAT</th>\n",
       "      <th>ESP</th>\n",
       "      <th>TCARBON_EQ</th>\n",
       "      <th>GYPSUM</th>\n",
       "      <th>ELEC_COND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>37.291667</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>3.458333</td>\n",
       "      <td>37.291667</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>10.1250</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>18.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>3.541667</td>\n",
       "      <td>37.291667</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>10.2500</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>15.000</td>\n",
       "      <td>18.166666</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>37.291667</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>10.0625</td>\n",
       "      <td>11.562500</td>\n",
       "      <td>14.875</td>\n",
       "      <td>18.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>3.708333</td>\n",
       "      <td>37.291667</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>10.1000</td>\n",
       "      <td>11.550000</td>\n",
       "      <td>14.800</td>\n",
       "      <td>18.150000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>36.791667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>36.791667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>36.791667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>36.791667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "      <td>7.625000</td>\n",
       "      <td>36.791667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row  col  longitude   latitude  tmin_2024_1  tmin_2024_2  tmin_2024_3  \\\n",
       "0      0  144   3.375000  37.291667     8.250000     8.250000      10.0000   \n",
       "1      0  145   3.458333  37.291667     8.250000     8.250000      10.1250   \n",
       "2      0  146   3.541667  37.291667     8.333333     8.333333      10.2500   \n",
       "3      0  147   3.625000  37.291667     8.250000     8.250000      10.0625   \n",
       "4      0  148   3.708333  37.291667     8.250000     8.250000      10.1000   \n",
       "..   ...  ...        ...        ...          ...          ...          ...   \n",
       "995    6  195   7.625000  36.791667     9.000000     9.000000      10.0000   \n",
       "996    6  195   7.625000  36.791667     9.000000     9.000000      10.0000   \n",
       "997    6  195   7.625000  36.791667     9.000000     9.000000      10.0000   \n",
       "998    6  195   7.625000  36.791667     9.000000     9.000000      10.0000   \n",
       "999    6  195   7.625000  36.791667     9.000000     9.000000      10.0000   \n",
       "\n",
       "     tmin_2024_4  tmin_2024_5  tmin_2024_6  ...  CEC_SOIL  CEC_CLAY  CEC_EFF  \\\n",
       "0      11.500000       15.000    18.000000  ...       NaN       NaN      NaN   \n",
       "1      11.750000       15.000    18.125000  ...       NaN       NaN      NaN   \n",
       "2      11.666667       15.000    18.166666  ...       NaN       NaN      NaN   \n",
       "3      11.562500       14.875    18.062500  ...       NaN       NaN      NaN   \n",
       "4      11.550000       14.800    18.150000  ...       NaN       NaN      NaN   \n",
       "..           ...          ...          ...  ...       ...       ...      ...   \n",
       "995    11.750000       15.000    18.500000  ...      18.0      41.0     18.0   \n",
       "996    11.750000       15.000    18.500000  ...      18.0      41.0     18.0   \n",
       "997    11.750000       15.000    18.500000  ...      18.0      41.0     18.0   \n",
       "998    11.750000       15.000    18.500000  ...      18.0      41.0     18.0   \n",
       "999    11.750000       15.000    18.500000  ...      18.0      41.0     18.0   \n",
       "\n",
       "      TEB  BSAT  ALUM_SAT  ESP  TCARBON_EQ  GYPSUM  ELEC_COND  \n",
       "0     NaN   NaN       NaN  NaN         NaN     NaN        NaN  \n",
       "1     NaN   NaN       NaN  NaN         NaN     NaN        NaN  \n",
       "2     NaN   NaN       NaN  NaN         NaN     NaN        NaN  \n",
       "3     NaN   NaN       NaN  NaN         NaN     NaN        NaN  \n",
       "4     NaN   NaN       NaN  NaN         NaN     NaN        NaN  \n",
       "..    ...   ...       ...  ...         ...     ...        ...  \n",
       "995  17.0  83.0       0.0  4.0         0.0     0.0        1.0  \n",
       "996  17.0  83.0       0.0  4.0         0.0     0.0        1.0  \n",
       "997  17.0  83.0       0.0  4.0         0.0     0.0        1.0  \n",
       "998  17.0  83.0       0.0  4.0         0.0     0.0        1.0  \n",
       "999  17.0  83.0       0.0  4.0         0.0     0.0        1.0  \n",
       "\n",
       "[1000 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db3991ad",
   "metadata": {},
   "source": [
    "hereeeeeeeeeeeeeeeeeeeeeeeeeeeeee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466e2410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate fire data points: 807777\n",
      "Soil data points: 7113536\n",
      "Final combined data points: 807777\n",
      "Missing soil data: 807777\n",
      "Dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# --- SIMPLER VERSION: MERGE DIRECTLY ON COORDINATES ---\n",
    "climate_fire_file = r\"D:\\S3\\data_mining\\projet2\\final_dataset.csv\"\n",
    "soil_file = r\"D:\\S3\\data_mining\\projet\\soil_data.csv\" \n",
    "\n",
    "# Load data\n",
    "climate_fire_df = pd.read_csv(climate_fire_file)\n",
    "soil_df = pd.read_csv(soil_file)\n",
    "\n",
    "# Round coordinates to avoid floating point precision issues\n",
    "climate_fire_df['longitude'] = climate_fire_df['longitude'].round(6)\n",
    "climate_fire_df['latitude'] = climate_fire_df['latitude'].round(6)\n",
    "soil_df['longitude'] = soil_df['longitude'].round(6)\n",
    "soil_df['latitude'] = soil_df['latitude'].round(6)\n",
    "\n",
    "print(f\"Climate fire data points: {len(climate_fire_df)}\")\n",
    "print(f\"Soil data points: {len(soil_df)}\")\n",
    "\n",
    "# Merge directly on coordinates\n",
    "final_combined_df = climate_fire_df.merge(\n",
    "    soil_df,\n",
    "    on=['longitude', 'latitude'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Final combined data points: {len(final_combined_df)}\")\n",
    "print(f\"Missing soil data: {final_combined_df['HWSD2_SMU_ID'].isna().sum()}\")\n",
    "\n",
    "# Save result\n",
    "final_combined_df.to_csv(r\"D:\\S3\\data_mining\\projet\\final_climate_fire_soil_data.csv\", index=False)\n",
    "print(\"Dataset saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e892c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding row and col to climate_fire data...\n",
      "Adding row and col to soil data...\n",
      "Climate fire data shape: (698106, 41)\n",
      "Soil data shape: (33476, 25)\n",
      "Climate fire unique grid cells: 33396\n",
      "Soil unique grid cells: 33476\n",
      "Final Combined DataFrame size: 698106\n",
      "Number of pixels with missing soil data: 1532\n",
      "\n",
      "Missing data per column:\n",
      "HWSD2_SMU_ID       1532\n",
      "COARSE             1532\n",
      "SAND               1532\n",
      "SILT               1532\n",
      "CLAY               1532\n",
      "TEXTURE_USDA     168565\n",
      "TEXTURE_SOTER      1532\n",
      "BULK               1532\n",
      "REF_BULK           1532\n",
      "ORG_CARBON         1532\n",
      "PH_WATER           1532\n",
      "TOTAL_N            1532\n",
      "CN_RATIO           1532\n",
      "CEC_SOIL           1532\n",
      "CEC_CLAY           1532\n",
      "CEC_EFF            1532\n",
      "TEB                1532\n",
      "BSAT               1532\n",
      "ALUM_SAT           1532\n",
      "ESP                1532\n",
      "TCARBON_EQ         1532\n",
      "GYPSUM             1532\n",
      "ELEC_COND          1532\n",
      "dtype: int64\n",
      "Final dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import pandas as pd\n",
    "from rasterio.transform import rowcol\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# --- 1. DEFINE FILE PATHS ---\n",
    "climate_fire_file = r\"D:\\S3\\data_mining\\projet2\\final_dataset.csv\"\n",
    "soil_file = r\"D:\\S3\\data_mining\\projet\\soil_data.csv\" \n",
    "tif_folder = r\"D:\\S3\\data_mining\\projet\\clipped_imputed_data2\\\\\" \n",
    "tif_files = sorted(glob.glob(tif_folder + \"*_imputed_local.tif\"))\n",
    "\n",
    "# --- 2. LOAD DATA ---\n",
    "climate_fire_df = pd.read_csv(climate_fire_file)\n",
    "soil_df = pd.read_csv(soil_file)\n",
    "\n",
    "# Get the Transformation matrix from the first climate TIF file\n",
    "with rasterio.open(tif_files[0]) as src:\n",
    "    transform = src.transform\n",
    "\n",
    "# --- 3. ADD ROW AND COL TO CLIMATE_FIRE_DF ---\n",
    "# Calculate 'row' and 'col' for the climate_fire data using the TIF transform\n",
    "print(\"Adding row and col to climate_fire data...\")\n",
    "rows, cols = rowcol(transform, climate_fire_df['longitude'], climate_fire_df['latitude'])\n",
    "climate_fire_df['row'] = rows\n",
    "climate_fire_df['col'] = cols\n",
    "\n",
    "# --- 4. MAP SOIL COORDINATES TO GRID INDICES ---\n",
    "# Calculate 'row' and 'col' for the soil data using the TIF transform\n",
    "print(\"Adding row and col to soil data...\")\n",
    "rows, cols = rowcol(transform, soil_df['longitude'], soil_df['latitude'])\n",
    "soil_df['row'] = rows\n",
    "soil_df['col'] = cols\n",
    "\n",
    "# --- 5. PREPARE SOIL DATA FOR MERGE ---\n",
    "# Keep all soil property columns and drop the redundant float coordinates\n",
    "soil_cols_to_keep = [\n",
    "    col for col in soil_df.columns \n",
    "    if col not in ['longitude', 'latitude']\n",
    "]\n",
    "# Ensure we only have unique grid cells for merging\n",
    "soil_df_final = soil_df[soil_cols_to_keep].drop_duplicates(subset=['row', 'col'])\n",
    "\n",
    "print(f\"Climate fire data shape: {climate_fire_df.shape}\")\n",
    "print(f\"Soil data shape: {soil_df_final.shape}\")\n",
    "print(f\"Climate fire unique grid cells: {climate_fire_df[['row', 'col']].drop_duplicates().shape[0]}\")\n",
    "print(f\"Soil unique grid cells: {soil_df_final[['row', 'col']].drop_duplicates().shape[0]}\")\n",
    "\n",
    "# --- 6. PERFORM THE FINAL MERGE ---\n",
    "# Use a LEFT JOIN to keep all rows in the climate_fire_df\n",
    "final_combined_df = climate_fire_df.merge(\n",
    "    soil_df_final,\n",
    "    on=['row', 'col'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- 7. CLEANUP AND SAVE ---\n",
    "print(f\"Final Combined DataFrame size: {len(final_combined_df)}\")\n",
    "print(f\"Number of pixels with missing soil data: {final_combined_df['HWSD2_SMU_ID'].isna().sum()}\")\n",
    "\n",
    "# Check which columns have missing data\n",
    "missing_data = final_combined_df.isnull().sum()\n",
    "print(\"\\nMissing data per column:\")\n",
    "print(missing_data[missing_data > 0])\n",
    "\n",
    "# Save the final, complete dataset\n",
    "final_combined_df.to_csv(r\"D:\\S3\\data_mining\\projet\\final_climate_fire_soil_data.csv\", index=False)\n",
    "print(\"Final dataset saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
