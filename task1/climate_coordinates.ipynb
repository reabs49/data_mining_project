{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1079a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing all TIFs to 2km grid\n",
      "============================================================\n",
      "Found 12 TIF files\n",
      "Creating 2km spacing grid...\n",
      "\n",
      "Processing: wc2.1_cruts4.09_5m_tmin_2024-01_imputed_local.tif -> tmin_2024_01_imputed_local\n",
      "Original grid: 37962 points (~7-9 km spacing)\n",
      "New grid: 956920 points (~2 km spacing)\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCTION 1: Convert TIF to dense 2km grid using interpolation\n",
    "# ============================================================================\n",
    "def tif_to_2km_grid(tif_path, variable_name='value', spacing_km=2):\n",
    "    \"\"\"\n",
    "    Convert a GeoTIFF to a DataFrame with 2km spacing grid.\n",
    "    Uses interpolation to create denser grid from original 5-minute data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tif_path : str\n",
    "        Path to the GeoTIFF file\n",
    "    variable_name : str\n",
    "        Name for the value column\n",
    "    spacing_km : float\n",
    "        Desired spacing in kilometers (default 2km)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame with coordinates every 2km\n",
    "    \"\"\"\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        # Read original data\n",
    "        data = src.read(1)\n",
    "        transform = src.transform\n",
    "        bounds = src.bounds  # (left, bottom, right, top)\n",
    "        \n",
    "        # Get original valid pixels\n",
    "        rows, cols = np.where(~np.isnan(data))\n",
    "        \n",
    "        # Convert to geographic coordinates\n",
    "        original_lons = []\n",
    "        original_lats = []\n",
    "        original_values = []\n",
    "        \n",
    "        for row, col in zip(rows, cols):\n",
    "            lon, lat = rasterio.transform.xy(transform, row, col, offset='center')\n",
    "            original_lons.append(lon)\n",
    "            original_lats.append(lat)\n",
    "            original_values.append(data[row, col])\n",
    "        \n",
    "        original_lons = np.array(original_lons)\n",
    "        original_lats = np.array(original_lats)\n",
    "        original_values = np.array(original_values)\n",
    "        \n",
    "        # Create new dense grid with 2km spacing\n",
    "        # Convert km to degrees (approximate at Algeria/Tunisia latitude ~35Â°N)\n",
    "        km_to_deg_lat = spacing_km / 111.0  # 1 degree latitude â‰ˆ 111 km\n",
    "        km_to_deg_lon = spacing_km / (111.0 * np.cos(np.radians(35)))  # Adjust for latitude\n",
    "        \n",
    "        # Create new grid\n",
    "        new_lons = np.arange(bounds.left, bounds.right, km_to_deg_lon)\n",
    "        new_lats = np.arange(bounds.bottom, bounds.top, km_to_deg_lat)\n",
    "        \n",
    "        # Create meshgrid\n",
    "        grid_lon, grid_lat = np.meshgrid(new_lons, new_lats)\n",
    "        \n",
    "        print(f\"Original grid: {len(original_lons)} points (~7-9 km spacing)\")\n",
    "        print(f\"New grid: {grid_lon.size} points (~{spacing_km} km spacing)\")\n",
    "        \n",
    "        # Interpolate values to new grid\n",
    "        grid_values = griddata(\n",
    "            points=(original_lons, original_lats),\n",
    "            values=original_values,\n",
    "            xi=(grid_lon, grid_lat),\n",
    "            method='cubic',  # Can use 'linear', 'cubic', or 'nearest'\n",
    "            fill_value=np.nan\n",
    "        )\n",
    "        \n",
    "        # Flatten arrays and remove NaN values\n",
    "        flat_lon = grid_lon.flatten()\n",
    "        flat_lat = grid_lat.flatten()\n",
    "        flat_values = grid_values.flatten()\n",
    "        \n",
    "        # Keep only valid values (within original data extent)\n",
    "        valid_mask = ~np.isnan(flat_values)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'longitude': flat_lon[valid_mask],\n",
    "            'latitude': flat_lat[valid_mask],\n",
    "            variable_name: flat_values[valid_mask]\n",
    "        })\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCTION 2: Process multiple TIFs to 2km grid\n",
    "# ============================================================================\n",
    "def process_multiple_tifs_to_2km(tif_folder, spacing_km=2):\n",
    "    \"\"\"\n",
    "    Process multiple TIF files and create a unified 2km spacing grid.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tif_folder : str\n",
    "        Path to folder containing TIF files\n",
    "    spacing_km : float\n",
    "        Desired spacing in kilometers\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame with all climate variables at 2km spacing\n",
    "    \"\"\"\n",
    "    tif_folder = Path(tif_folder)\n",
    "    tif_files = sorted(tif_folder.glob('*.tif'))\n",
    "    \n",
    "    if len(tif_files) == 0:\n",
    "        raise ValueError(f\"No TIF files found in {tif_folder}\")\n",
    "    \n",
    "    print(f\"Found {len(tif_files)} TIF files\")\n",
    "    print(f\"Creating {spacing_km}km spacing grid...\\n\")\n",
    "    \n",
    "    # Process first file to establish grid\n",
    "    first_file = tif_files[0]\n",
    "    var_name = extract_variable_name(first_file.stem)\n",
    "    print(f\"Processing: {first_file.name} -> {var_name}\")\n",
    "    \n",
    "    result_df = tif_to_2km_grid(str(first_file), var_name, spacing_km)\n",
    "    \n",
    "    # Process remaining files\n",
    "    for tif_file in tif_files[1:]:\n",
    "        var_name = extract_variable_name(tif_file.stem)\n",
    "        print(f\"\\nProcessing: {tif_file.name} -> {var_name}\")\n",
    "        \n",
    "        df = tif_to_2km_grid(str(tif_file), var_name, spacing_km)\n",
    "        \n",
    "        # Merge on coordinates (with small tolerance for floating point)\n",
    "        result_df = result_df.merge(\n",
    "            df,\n",
    "            on=['longitude', 'latitude'],\n",
    "            how='outer'\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Final DataFrame shape: {result_df.shape}\")\n",
    "    print(f\"Grid spacing: ~{spacing_km} km\")\n",
    "    print(f\"Total grid points: {len(result_df)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "\n",
    "def resample_tif_to_2km(tif_path, variable_name, output_resolution_km=2):\n",
    "    \"\"\"\n",
    "    Resample a TIF to 2km resolution directly using rasterio.\n",
    "    This is FASTER than the interpolation method above.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tif_path : str\n",
    "        Path to input TIF\n",
    "    variable_name : str\n",
    "        Variable name\n",
    "    output_resolution_km : float\n",
    "        Desired resolution in km\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "    \"\"\"\n",
    "    from rasterio.enums import Resampling\n",
    "    \n",
    "    with rasterio.open(tif_path) as src:\n",
    "        # Calculate new dimensions\n",
    "        # Convert km to degrees\n",
    "        km_to_deg = output_resolution_km / 111.0\n",
    "        \n",
    "        # Calculate scale factor\n",
    "        original_res = src.res[0]  # Original resolution in degrees\n",
    "        scale_factor = original_res / km_to_deg\n",
    "        \n",
    "        # New dimensions\n",
    "        new_width = int(src.width * scale_factor)\n",
    "        new_height = int(src.height * scale_factor)\n",
    "        \n",
    "        # Read and resample\n",
    "        data = src.read(\n",
    "            1,\n",
    "            out_shape=(new_height, new_width),\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        \n",
    "        # Calculate new transform\n",
    "        new_transform = src.transform * src.transform.scale(\n",
    "            (src.width / new_width),\n",
    "            (src.height / new_height)\n",
    "        )\n",
    "        \n",
    "        # Extract coordinates\n",
    "        rows, cols = np.where(~np.isnan(data))\n",
    "        \n",
    "        lons = []\n",
    "        lats = []\n",
    "        values = []\n",
    "        \n",
    "        for row, col in zip(rows, cols):\n",
    "            lon, lat = rasterio.transform.xy(new_transform, row, col, offset='center')\n",
    "            lons.append(lon)\n",
    "            lats.append(lat)\n",
    "            values.append(data[row, col])\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'longitude': lons,\n",
    "            'latitude': lats,\n",
    "            variable_name: values\n",
    "        })\n",
    "        \n",
    "        print(f\"Resampled from {src.height}x{src.width} to {new_height}x{new_width}\")\n",
    "        print(f\"Original resolution: ~{original_res * 111:.1f} km\")\n",
    "        print(f\"New resolution: ~{output_resolution_km} km\")\n",
    "        print(f\"Total points: {len(df)}\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "def extract_variable_name(filename):\n",
    "    parts = filename.replace('-', '_').split('_')\n",
    "    for i, part in enumerate(parts):\n",
    "        if part in ['tmin', 'tmax', 'prec']:\n",
    "            variable = part\n",
    "            if i + 1 < len(parts):\n",
    "                date_parts = '_'.join(parts[i+1:])\n",
    "                return f\"{variable}_{date_parts}\"\n",
    "    return filename\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "   \n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Processing all TIFs to 2km grid\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    climate_2km_df = process_multiple_tifs_to_2km(\n",
    "        r\"D:\\S3\\data_mining\\projet\\clipped_imputed_data2/\",\n",
    "        spacing_km=2\n",
    "    )\n",
    "    \n",
    "    climate_2km_df.to_csv('climate_2km_grid.csv', index=False)\n",
    "    print(\"\\nSaved to: climate_2km_grid.csv\")\n",
    "    \n",
    "    climate_2km_gdf = gpd.GeoDataFrame(\n",
    "        climate_2km_df,\n",
    "        geometry=[Point(xy) for xy in zip(climate_2km_df.longitude, climate_2km_df.latitude)],\n",
    "        crs=\"EPSG:4326\"\n",
    "    )\n",
    "    \n",
    "    climate_2km_gdf.to_file('climate_2km_grid.geojson', driver='GeoJSON')\n",
    "    print(\"Saved to: climate_2km_grid.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e649f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ¡ï¸  TEMPERATURE DATA TO 2KM GRID CONVERSION\n",
      "============================================================\n",
      "ðŸ“ Found 12 TIF files\n",
      "ðŸŽ¯ Creating 2km spacing grid using resample method...\n",
      "\n",
      "ðŸ“Š FILE ANALYSIS:\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-01.tif â†’ prec_jan\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-02.tif â†’ prec_feb\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-03.tif â†’ prec_mar\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-04.tif â†’ prec_apr\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-05.tif â†’ prec_may\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-06.tif â†’ prec_jun\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-07.tif â†’ prec_jul\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-08.tif â†’ prec_aug\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-09.tif â†’ prec_sep\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-10.tif â†’ prec_oct\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-11.tif â†’ prec_nov\n",
      "   ðŸ“„ wc2.1_cruts4.09_5m_prec_2024-12.tif â†’ prec_dec\n",
      "\n",
      "ðŸ”„ PROCESSING FILES:\n",
      "\n",
      "[1/12] prec_jan\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_jan\n",
      "\n",
      "[2/12] prec_feb\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_feb\n",
      "\n",
      "[3/12] prec_mar\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_mar\n",
      "\n",
      "[4/12] prec_apr\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_apr\n",
      "\n",
      "[5/12] prec_may\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_may\n",
      "\n",
      "[6/12] prec_jun\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_jun\n",
      "\n",
      "[7/12] prec_jul\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_jul\n",
      "\n",
      "[8/12] prec_aug\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_aug\n",
      "\n",
      "[9/12] prec_sep\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_sep\n",
      "\n",
      "[10/12] prec_oct\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_oct\n",
      "\n",
      "[11/12] prec_nov\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_nov\n",
      "\n",
      "[12/12] prec_dec\n",
      "   Original resolution: 0.0833Â° (~9.3 km)\n",
      "   âœ… 698,106 points | Variable: prec_dec\n",
      "\n",
      "ðŸ”„ MERGING 12 DATASETS...\n",
      "   Merge 2: 698,106 â†’ 698,106 points\n",
      "   Merge 3: 698,106 â†’ 698,106 points\n",
      "   Merge 4: 698,106 â†’ 698,106 points\n",
      "   Merge 5: 698,106 â†’ 698,106 points\n",
      "   Merge 6: 698,106 â†’ 698,106 points\n",
      "   Merge 7: 698,106 â†’ 698,106 points\n",
      "   Merge 8: 698,106 â†’ 698,106 points\n",
      "   Merge 9: 698,106 â†’ 698,106 points\n",
      "   Merge 10: 698,106 â†’ 698,106 points\n",
      "   Merge 11: 698,106 â†’ 698,106 points\n",
      "   Merge 12: 698,106 â†’ 698,106 points\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š FINAL RESULTS:\n",
      "   Grid spacing: ~2 km\n",
      "   Total grid points: 698,106\n",
      "   Temperature variables: 12\n",
      "   Variables: prec_apr, prec_aug, prec_dec, prec_feb, prec_jan, prec_jul, prec_jun, prec_mar, prec_may, prec_nov, prec_oct, prec_sep\n",
      "============================================================\n",
      "\n",
      "ðŸ” DATA VALIDATION:\n",
      "   Grid points: 698,106\n",
      "   Columns: 14\n",
      "   Longitude: -8.66 to 11.99\n",
      "   Latitude: 19.01 to 37.32\n",
      "   prec_jan: 0.0 to 137.1 (mean: 4.3)\n",
      "   prec_feb: 0.0 to 262.3 (mean: 8.6)\n",
      "   prec_mar: 0.0 to 48.6 (mean: 4.4)\n",
      "   prec_apr: 0.0 to 91.5 (mean: 6.3)\n",
      "   prec_may: 0.0 to 41.1 (mean: 3.7)\n",
      "   prec_jun: 0.0 to 20.8 (mean: 2.2)\n",
      "   prec_jul: 0.0 to 24.9 (mean: 1.1)\n",
      "   prec_aug: 0.0 to 39.6 (mean: 4.2)\n",
      "   prec_sep: 0.0 to 81.9 (mean: 10.4)\n",
      "   prec_oct: 0.0 to 77.1 (mean: 6.4)\n",
      "   prec_nov: 0.0 to 93.8 (mean: 4.9)\n",
      "   prec_dec: 0.0 to 214.1 (mean: 7.1)\n",
      "   Missing values: 0\n",
      "\n",
      "ðŸ’¾ CSV saved to: temperature_percipitation_2km_grid.csv\n",
      "ðŸ—ºï¸  GeoJSON saved to: temperature_percepitation_2km_grid.geojson\n",
      "\n",
      "ðŸŽ‰ PROCESSING COMPLETE!\n",
      "   Final dataset: 698,106 points\n",
      "   Variables: 12 temperature columns\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def km_to_degrees(lat, spacing_km):\n",
    "    \n",
    "    km_per_deg_lat = 111.0\n",
    "    km_per_deg_lon = 111.0 * np.cos(np.radians(lat))\n",
    "    \n",
    "    deg_spacing_lon = spacing_km / km_per_deg_lon\n",
    "    deg_spacing_lat = spacing_km / km_per_deg_lat\n",
    "    \n",
    "    return deg_spacing_lon, deg_spacing_lat\n",
    "\n",
    "def extract_month_from_filename(filename):\n",
    "    \n",
    "    name = Path(filename).stem.lower()\n",
    "    \n",
    "    month_map = {\n",
    "        '01': 'jan', '02': 'feb', '03': 'mar', '04': 'apr',\n",
    "        '05': 'may', '06': 'jun', '07': 'jul', '08': 'aug', \n",
    "        '09': 'sep', '10': 'oct', '11': 'nov', '12': 'dec'\n",
    "    }\n",
    "    \n",
    "    if 'tmin' in name:\n",
    "        var_type = 'tmin'\n",
    "    elif 'tmax' in name:\n",
    "        var_type = 'tmax'\n",
    "    elif 'tavg' in name:\n",
    "        var_type = 'tavg'\n",
    "    elif 'prec' in name:\n",
    "        var_type = 'prec'\n",
    "    else:\n",
    "        var_type = 'unknown'\n",
    "    \n",
    "    for month_num, month_name in month_map.items():\n",
    "        if f'-{month_num}' in name or f'_{month_num}' in name:\n",
    "            return f\"{var_type}_{month_name}\"\n",
    "    \n",
    "    return name.replace('-', '_').replace(' ', '_')\n",
    "\n",
    "\n",
    "def tif_to_2km_grid(tif_path, variable_name=None, spacing_km=2, method='linear'):\n",
    "   \n",
    "    if variable_name is None:\n",
    "        variable_name = extract_month_from_filename(tif_path)\n",
    "    \n",
    "    with rasterio.open(tif_path) as src:\n",
    "        data = src.read(1)\n",
    "        transform = src.transform\n",
    "        bounds = src.bounds\n",
    "        \n",
    "        orig_res_deg = src.res[0]\n",
    "        orig_res_km = orig_res_deg * 111.0\n",
    "        print(f\"   Original resolution: {orig_res_deg:.4f}Â° (~{orig_res_km:.1f} km)\")\n",
    "        \n",
    "        if spacing_km < orig_res_km:\n",
    "            print(\"   âš ï¸  Note: Creating finer grid via interpolation\")\n",
    "        \n",
    "        rows, cols = np.where(~np.isnan(data) & (data != src.nodata))\n",
    "        \n",
    "        if len(rows) == 0:\n",
    "            raise ValueError(\"No valid data points found\")\n",
    "        \n",
    "        original_lons, original_lats, original_values = [], [], []\n",
    "        \n",
    "        for row, col in zip(rows, cols):\n",
    "            lon, lat = rasterio.transform.xy(transform, row, col, offset='center')\n",
    "            original_lons.append(lon)\n",
    "            original_lats.append(lat)\n",
    "            original_values.append(data[row, col])\n",
    "        \n",
    "        original_lons = np.array(original_lons)\n",
    "        original_lats = np.array(original_lats)\n",
    "        original_values = np.array(original_values)\n",
    "        \n",
    "        deg_spacing_lon, deg_spacing_lat = km_to_degrees(30, spacing_km)\n",
    "        \n",
    "        new_lons = np.arange(bounds.left, bounds.right, deg_spacing_lon)\n",
    "        new_lats = np.arange(bounds.bottom, bounds.top, deg_spacing_lat)\n",
    "        \n",
    "        # Create meshgrid for interpolation\n",
    "        grid_lon, grid_lat = np.meshgrid(new_lons, new_lats)\n",
    "        \n",
    "        # Interpolate values to new grid\n",
    "        grid_values = griddata(\n",
    "            points=(original_lons, original_lats),\n",
    "            values=original_values,\n",
    "            xi=(grid_lon, grid_lat),\n",
    "            method=method,\n",
    "            fill_value=np.nan\n",
    "        )\n",
    "        \n",
    "        # Flatten arrays and remove NaN values\n",
    "        flat_lon = grid_lon.flatten()\n",
    "        flat_lat = grid_lat.flatten()\n",
    "        flat_values = grid_values.flatten()\n",
    "        \n",
    "        valid_mask = ~np.isnan(flat_values)\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'longitude': flat_lon[valid_mask],\n",
    "            'latitude': flat_lat[valid_mask],\n",
    "            variable_name: flat_values[valid_mask]\n",
    "        })\n",
    "        \n",
    "        print(f\"   âœ… {len(df):,} points | Variable: {variable_name}\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "def resample_tif_to_2km(tif_path, variable_name=None, output_resolution_km=2):\n",
    "    \"\"\"\n",
    "    Resample TIF to target resolution using rasterio's built-in resampling.\n",
    "    \"\"\"\n",
    "    from rasterio.enums import Resampling\n",
    "    \n",
    "    if variable_name is None:\n",
    "        variable_name = extract_month_from_filename(tif_path)\n",
    "    \n",
    "    with rasterio.open(tif_path) as src:\n",
    "        # Calculate original resolution\n",
    "        orig_res_deg = src.res[0]\n",
    "        orig_res_km = orig_res_deg * 111.0\n",
    "        \n",
    "        print(f\"   Original resolution: {orig_res_deg:.4f}Â° (~{orig_res_km:.1f} km)\")\n",
    "        \n",
    "        # Calculate degree spacing\n",
    "        deg_spacing_lon, deg_spacing_lat = km_to_degrees(30, output_resolution_km)\n",
    "        target_res_deg = min(deg_spacing_lon, deg_spacing_lat)\n",
    "        \n",
    "        # Calculate scale factor\n",
    "        scale_factor = orig_res_deg / target_res_deg\n",
    "        \n",
    "        # New dimensions\n",
    "        new_width = int(src.width * scale_factor)\n",
    "        new_height = int(src.height * scale_factor)\n",
    "        \n",
    "        # Read and resample\n",
    "        data = src.read(\n",
    "            1,\n",
    "            out_shape=(new_height, new_width),\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        \n",
    "        # Calculate new transform\n",
    "        new_transform = src.transform * src.transform.scale(\n",
    "            (src.width / new_width),\n",
    "            (src.height / new_height)\n",
    "        )\n",
    "        \n",
    "        # Extract coordinates and values\n",
    "        rows, cols = np.where(~np.isnan(data) & (data != src.nodata))\n",
    "        \n",
    "        lons, lats, values = [], [], []\n",
    "        \n",
    "        for row, col in zip(rows, cols):\n",
    "            lon, lat = rasterio.transform.xy(new_transform, row, col, offset='center')\n",
    "            lons.append(lon)\n",
    "            lats.append(lat)\n",
    "            values.append(data[row, col])\n",
    "        \n",
    "        df = pd.DataFrame({\n",
    "            'longitude': lons,\n",
    "            'latitude': lats,\n",
    "            variable_name: values\n",
    "        })\n",
    "        \n",
    "        print(f\"   âœ… {len(df):,} points | Variable: {variable_name}\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# ============================================================================\n",
    "# BATCH PROCESSING - SIMPLIFIED\n",
    "# ============================================================================\n",
    "\n",
    "def process_temperature_data(tif_folder, spacing_km=2, method='resample'):\n",
    "    \"\"\"\n",
    "    Process all temperature TIF files and create unified 2km grid.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tif_folder : str\n",
    "        Path to folder containing TIF files\n",
    "    spacing_km : float\n",
    "        Desired spacing in kilometers\n",
    "    method : str\n",
    "        'interpolate' or 'resample'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame with all temperature variables at 2km spacing\n",
    "    \"\"\"\n",
    "    tif_folder = Path(tif_folder)\n",
    "    tif_files = sorted(tif_folder.glob('*.tif'))\n",
    "    \n",
    "    if len(tif_files) == 0:\n",
    "        raise ValueError(f\"âŒ No TIF files found in {tif_folder}\")\n",
    "    \n",
    "    print(f\"ðŸ“ Found {len(tif_files)} TIF files\")\n",
    "    print(f\"ðŸŽ¯ Creating {spacing_km}km spacing grid using {method} method...\")\n",
    "    print()\n",
    "    \n",
    "    # First, analyze the files\n",
    "    print(\"ðŸ“Š FILE ANALYSIS:\")\n",
    "    for tif_file in tif_files:\n",
    "        var_name = extract_month_from_filename(tif_file)\n",
    "        print(f\"   ðŸ“„ {tif_file.name} â†’ {var_name}\")\n",
    "    \n",
    "    print(\"\\nðŸ”„ PROCESSING FILES:\")\n",
    "    \n",
    "    # Process all files and store in a list\n",
    "    all_dataframes = []\n",
    "    \n",
    "    for i, tif_file in enumerate(tif_files, 1):\n",
    "        var_name = extract_month_from_filename(tif_file)\n",
    "        print(f\"\\n[{i}/{len(tif_files)}] {var_name}\")\n",
    "        \n",
    "        try:\n",
    "            if method == 'interpolate':\n",
    "                df = tif_to_2km_grid(str(tif_file), var_name, spacing_km)\n",
    "            else:\n",
    "                df = resample_tif_to_2km(str(tif_file), var_name, spacing_km)\n",
    "            \n",
    "            # Round coordinates to avoid floating point issues\n",
    "            df['longitude'] = df['longitude'].round(6)\n",
    "            df['latitude'] = df['latitude'].round(6)\n",
    "            \n",
    "            all_dataframes.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Failed: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_dataframes:\n",
    "        raise ValueError(\"âŒ No files were successfully processed\")\n",
    "    \n",
    "    print(f\"\\nðŸ”„ MERGING {len(all_dataframes)} DATASETS...\")\n",
    "    \n",
    "    # Start with first dataframe as base\n",
    "    result_df = all_dataframes[0]\n",
    "    \n",
    "    # Merge all other dataframes\n",
    "    for i, df in enumerate(all_dataframes[1:], 2):\n",
    "        # Merge on coordinates\n",
    "        before_count = len(result_df)\n",
    "        result_df = result_df.merge(\n",
    "            df,\n",
    "            on=['longitude', 'latitude'],\n",
    "            how='inner'\n",
    "        )\n",
    "        after_count = len(result_df)\n",
    "        \n",
    "        print(f\"   Merge {i}: {before_count:,} â†’ {after_count:,} points\")\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ“Š FINAL RESULTS:\")\n",
    "    print(f\"   Grid spacing: ~{spacing_km} km\")\n",
    "    print(f\"   Total grid points: {len(result_df):,}\")\n",
    "    print(f\"   Temperature variables: {len(result_df.columns) - 2}\")\n",
    "    \n",
    "    # List all temperature columns\n",
    "    temp_columns = [col for col in result_df.columns if col not in ['longitude', 'latitude']]\n",
    "    print(f\"   Variables: {', '.join(sorted(temp_columns))}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# ============================================================================\n",
    "# QUALITY CONTROL\n",
    "# ============================================================================\n",
    "\n",
    "def validate_temperature_grid(df):\n",
    "    \"\"\"\n",
    "    Validate the temperature grid data.\n",
    "    \"\"\"\n",
    "    print(\"\\nðŸ” DATA VALIDATION:\")\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"   Grid points: {len(df):,}\")\n",
    "    print(f\"   Columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Coordinate ranges\n",
    "    lon_range = f\"{df.longitude.min():.2f} to {df.longitude.max():.2f}\"\n",
    "    lat_range = f\"{df.latitude.min():.2f} to {df.latitude.max():.2f}\"\n",
    "    print(f\"   Longitude: {lon_range}\")\n",
    "    print(f\"   Latitude: {lat_range}\")\n",
    "    \n",
    "    # Temperature statistics\n",
    "    temp_columns = [col for col in df.columns if col not in ['longitude', 'latitude']]\n",
    "    for col in temp_columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"   {col}: {df[col].min():.1f} to {df[col].max():.1f} (mean: {df[col].mean():.1f})\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing = df.isnull().sum().sum()\n",
    "    print(f\"   Missing values: {missing}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Configuration\n",
    "    TIF_FOLDER = r\"D:\\S3\\data_mining\\projet\\percepitation_climate\\precipitations\"\n",
    "    OUTPUT_CSV = \"temperature_percipitation_2km_grid.csv\"\n",
    "    OUTPUT_GEOJSON = \"temperature_percepitation_2km_grid.geojson\"\n",
    "    SPACING_KM = 2\n",
    "    METHOD = \"resample\"  # \"interpolate\" or \"resample\"\n",
    "    \n",
    "    print(\"ðŸŒ¡ï¸  TEMPERATURE DATA TO 2KM GRID CONVERSION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Process all temperature files\n",
    "        temperature_df = process_temperature_data(\n",
    "            TIF_FOLDER,\n",
    "            spacing_km=SPACING_KM,\n",
    "            method=METHOD\n",
    "        )\n",
    "        \n",
    "        # Validate the grid\n",
    "        validate_temperature_grid(temperature_df)\n",
    "        \n",
    "        # Save as CSV\n",
    "        temperature_df.to_csv(OUTPUT_CSV, index=False)\n",
    "        print(f\"\\nðŸ’¾ CSV saved to: {OUTPUT_CSV}\")\n",
    "        \n",
    "        # Save as GeoJSON (optional)\n",
    "        geometry = [Point(xy) for xy in zip(temperature_df.longitude, temperature_df.latitude)]\n",
    "        temperature_gdf = gpd.GeoDataFrame(\n",
    "            temperature_df,\n",
    "            geometry=geometry,\n",
    "            crs=\"EPSG:4326\"\n",
    "        )\n",
    "        \n",
    "        temperature_gdf.to_file(OUTPUT_GEOJSON, driver='GeoJSON')\n",
    "        print(f\"ðŸ—ºï¸  GeoJSON saved to: {OUTPUT_GEOJSON}\")\n",
    "        \n",
    "        # Final summary\n",
    "        print(f\"\\nðŸŽ‰ PROCESSING COMPLETE!\")\n",
    "        print(f\"   Final dataset: {len(temperature_df):,} points\")\n",
    "        print(f\"   Variables: {len(temperature_df.columns) - 2} temperature columns\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ERROR: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff8ad4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged 698,106 points\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simple one-liner merge\n",
    "tmin = pd.read_csv(r\"D:\\S3\\data_mining\\projet2\\temperature_2km_grid.csv\")\n",
    "tmax = pd.read_csv(r\"D:\\S3\\data_mining\\projet2\\temperature_max_2km_grid.csv\")\n",
    "prec = pd.read_csv(r\"D:\\S3\\data_mining\\projet2\\temperature_percipitation_2km_grid.csv\")\n",
    "\n",
    "# Round coordinates\n",
    "for df in [tmin, tmax, prec]:\n",
    "    df['longitude'] = df['longitude'].round(6)\n",
    "    df['latitude'] = df['latitude'].round(6)\n",
    "\n",
    "# Chain the merges\n",
    "complete_climate = tmin.merge(tmax, on=['longitude', 'latitude'])\\\n",
    "                      .merge(prec, on=['longitude', 'latitude'])\n",
    "\n",
    "print(f\"âœ… Merged {len(complete_climate):,} points\")\n",
    "complete_climate.to_csv(\"complete_climate.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea24a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>tmin_jan</th>\n",
       "      <th>tmin_feb</th>\n",
       "      <th>tmin_mar</th>\n",
       "      <th>tmin_apr</th>\n",
       "      <th>tmin_may</th>\n",
       "      <th>tmin_jun</th>\n",
       "      <th>tmin_jul</th>\n",
       "      <th>tmin_aug</th>\n",
       "      <th>...</th>\n",
       "      <th>prec_apr</th>\n",
       "      <th>prec_may</th>\n",
       "      <th>prec_jun</th>\n",
       "      <th>prec_jul</th>\n",
       "      <th>prec_aug</th>\n",
       "      <th>prec_sep</th>\n",
       "      <th>prec_oct</th>\n",
       "      <th>prec_nov</th>\n",
       "      <th>prec_dec</th>\n",
       "      <th>is_fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.558559</td>\n",
       "      <td>37.32432</td>\n",
       "      <td>8.449325</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.449325</td>\n",
       "      <td>11.199325</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.449324</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.357433</td>\n",
       "      <td>20.113176</td>\n",
       "      <td>4.294932</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>6.980405</td>\n",
       "      <td>33.809800</td>\n",
       "      <td>55.512160</td>\n",
       "      <td>40.542570</td>\n",
       "      <td>92.953040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.576577</td>\n",
       "      <td>37.32432</td>\n",
       "      <td>8.395270</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.395270</td>\n",
       "      <td>11.145270</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.395270</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.152027</td>\n",
       "      <td>19.967230</td>\n",
       "      <td>4.289527</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>7.012838</td>\n",
       "      <td>33.793583</td>\n",
       "      <td>55.685135</td>\n",
       "      <td>40.347973</td>\n",
       "      <td>92.396286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.594595</td>\n",
       "      <td>37.32432</td>\n",
       "      <td>8.341216</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.341216</td>\n",
       "      <td>11.091216</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.341217</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.946620</td>\n",
       "      <td>19.821283</td>\n",
       "      <td>4.284122</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>7.045270</td>\n",
       "      <td>33.777367</td>\n",
       "      <td>55.858110</td>\n",
       "      <td>40.153378</td>\n",
       "      <td>91.839530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.612613</td>\n",
       "      <td>37.32432</td>\n",
       "      <td>8.287162</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.287162</td>\n",
       "      <td>11.037162</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.287163</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.741220</td>\n",
       "      <td>19.675339</td>\n",
       "      <td>4.278716</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>7.077703</td>\n",
       "      <td>33.761150</td>\n",
       "      <td>56.031082</td>\n",
       "      <td>39.958786</td>\n",
       "      <td>91.282770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.630631</td>\n",
       "      <td>37.32432</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.233109</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.233109</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.515540</td>\n",
       "      <td>19.551352</td>\n",
       "      <td>4.268243</td>\n",
       "      <td>1.036824</td>\n",
       "      <td>7.125338</td>\n",
       "      <td>33.780407</td>\n",
       "      <td>56.204056</td>\n",
       "      <td>39.833447</td>\n",
       "      <td>90.737840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  tmin_jan  tmin_feb  tmin_mar   tmin_apr  tmin_may  \\\n",
       "0   9.558559  37.32432  8.449325       8.5  9.449325  11.199325      15.0   \n",
       "1   9.576577  37.32432  8.395270       8.5  9.395270  11.145270      15.0   \n",
       "2   9.594595  37.32432  8.341216       8.5  9.341216  11.091216      15.0   \n",
       "3   9.612613  37.32432  8.287162       8.5  9.287162  11.037162      15.0   \n",
       "4   9.630631  37.32432  8.250000       8.5  9.233109  11.000000      15.0   \n",
       "\n",
       "    tmin_jun  tmin_jul  tmin_aug  ...   prec_apr   prec_may  prec_jun  \\\n",
       "0  18.449324      22.0      22.0  ...  33.357433  20.113176  4.294932   \n",
       "1  18.395270      22.0      22.0  ...  33.152027  19.967230  4.289527   \n",
       "2  18.341217      22.0      22.0  ...  32.946620  19.821283  4.284122   \n",
       "3  18.287163      22.0      22.0  ...  32.741220  19.675339  4.278716   \n",
       "4  18.233109      22.0      22.0  ...  32.515540  19.551352  4.268243   \n",
       "\n",
       "   prec_jul  prec_aug   prec_sep   prec_oct   prec_nov   prec_dec  is_fire  \n",
       "0  1.025000  6.980405  33.809800  55.512160  40.542570  92.953040        0  \n",
       "1  1.025000  7.012838  33.793583  55.685135  40.347973  92.396286        0  \n",
       "2  1.025000  7.045270  33.777367  55.858110  40.153378  91.839530        0  \n",
       "3  1.025000  7.077703  33.761150  56.031082  39.958786  91.282770        0  \n",
       "4  1.036824  7.125338  33.780407  56.204056  39.833447  90.737840        0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_climate[\"is_fire\"] = 0\n",
    "complete_climate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f907c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "fires = pd.read_csv(r\"D:\\S3\\data_mining\\projet\\clean_data\\fire_alg_tunis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d88df8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fires['is_fire_fire'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a3b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged 12924 fire points with 698106 climate points\n",
      "âœ… Found 6353 fire-affected grid points\n",
      "âœ… Saved to: final_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# SIMPLEST POSSIBLE VERSION\n",
    "def simple_fire_merge(climate_file, fire_file, output_file, max_distance_km=2):\n",
    "    \"\"\"\n",
    "    Ultra-simple fire-climate merge\n",
    "    \"\"\"\n",
    "    # Load files\n",
    "    climate = pd.read_csv(climate_file)\n",
    "    fires = pd.read_csv(fire_file)\n",
    "    \n",
    "    # Find coordinate columns\n",
    "    clon = [c for c in climate.columns if 'lon' in c.lower()][0]\n",
    "    clat = [c for c in climate.columns if 'lat' in c.lower()][0]\n",
    "    flon = [c for c in fires.columns if 'lon' in c.lower()][0] \n",
    "    flat = [c for c in fires.columns if 'lat' in c.lower()][0]\n",
    "    \n",
    "    # Convert km to degrees (approximate)\n",
    "    max_distance_deg = max_distance_km * 0.009\n",
    "    \n",
    "    # Start with all points as non-fire\n",
    "    climate['is_fire'] = 0\n",
    "    \n",
    "    # For each fire, find nearby climate points\n",
    "    for _, fire in fires.iterrows():\n",
    "        # Calculate distance to all climate points\n",
    "        distance = np.sqrt(\n",
    "            (climate[clat] - fire[flat])**2 + \n",
    "            (climate[clon] - fire[flon])**2\n",
    "        )\n",
    "        \n",
    "        # Mark nearby points as fire\n",
    "        climate.loc[distance <= max_distance_deg, 'is_fire'] = 1\n",
    "    \n",
    "    # Save result\n",
    "    climate.to_csv(output_file, index=False)\n",
    "    print(f\"âœ… Merged {len(fires)} fire points with {len(climate)} climate points\")\n",
    "    print(f\"âœ… Found {climate['is_fire'].sum()} fire-affected grid points\")\n",
    "    print(f\"âœ… Saved to: {output_file}\")\n",
    "    \n",
    "    return climate\n",
    "\n",
    "# USAGE:\n",
    "if __name__ == \"__main__\":\n",
    "    simple_fire_merge(\n",
    "        climate_file=\"D:\\S3\\data_mining\\projet2\\complete_climate.csv\",\n",
    "        fire_file=r\"D:\\S3\\data_mining\\projet\\clean_data\\fire_alg_tunis.csv\", \n",
    "        output_file=\"final_dataset.csv\",\n",
    "        max_distance_km=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af58f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_df = pd.read_csv(r\"D:\\S3\\data_mining\\projet2\\temperature_2km_grid.csv\")\n",
    "fires = pd.read_csv(r\"D:\\S3\\data_mining\\projet\\clean_data\\fire_alg_tunis.csv\")\n",
    "\n",
    "fire_climate_df = climate_df.merge(\n",
    "    fires[['longitude','latitude',  'is_fire']],\n",
    "    left_on=['longitude' , 'latitude' ],           # Columns in pivot_df (climate data)\n",
    "    right_on=['longitude' ,'latitude'], # Columns in fires DataFrame\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58f98c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>tmin_jan</th>\n",
       "      <th>tmin_feb</th>\n",
       "      <th>tmin_mar</th>\n",
       "      <th>tmin_apr</th>\n",
       "      <th>tmin_may</th>\n",
       "      <th>tmin_jun</th>\n",
       "      <th>tmin_jul</th>\n",
       "      <th>tmin_aug</th>\n",
       "      <th>tmin_sep</th>\n",
       "      <th>tmin_oct</th>\n",
       "      <th>tmin_nov</th>\n",
       "      <th>tmin_dec</th>\n",
       "      <th>is_fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.378378</td>\n",
       "      <td>37.32432</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.005068</td>\n",
       "      <td>11.510135</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.005068</td>\n",
       "      <td>21.010136</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.255068</td>\n",
       "      <td>16.755068</td>\n",
       "      <td>13.25</td>\n",
       "      <td>6.760135</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.396396</td>\n",
       "      <td>37.32432</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.032095</td>\n",
       "      <td>11.564189</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.032095</td>\n",
       "      <td>21.064190</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.282095</td>\n",
       "      <td>16.782095</td>\n",
       "      <td>13.25</td>\n",
       "      <td>6.814189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.414414</td>\n",
       "      <td>37.32432</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.059122</td>\n",
       "      <td>11.618243</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.059122</td>\n",
       "      <td>21.118244</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.309122</td>\n",
       "      <td>16.809122</td>\n",
       "      <td>13.25</td>\n",
       "      <td>6.868243</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.432432</td>\n",
       "      <td>37.32432</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.086148</td>\n",
       "      <td>11.672298</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.086150</td>\n",
       "      <td>21.172297</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.336150</td>\n",
       "      <td>16.836150</td>\n",
       "      <td>13.25</td>\n",
       "      <td>6.922297</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.450450</td>\n",
       "      <td>37.32432</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.25</td>\n",
       "      <td>10.113175</td>\n",
       "      <td>11.726352</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.113176</td>\n",
       "      <td>21.226350</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.363176</td>\n",
       "      <td>16.863176</td>\n",
       "      <td>13.25</td>\n",
       "      <td>6.976351</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  tmin_jan  tmin_feb   tmin_mar   tmin_apr  tmin_may  \\\n",
       "0   3.378378  37.32432      8.25      8.25  10.005068  11.510135      15.0   \n",
       "1   3.396396  37.32432      8.25      8.25  10.032095  11.564189      15.0   \n",
       "2   3.414414  37.32432      8.25      8.25  10.059122  11.618243      15.0   \n",
       "3   3.432432  37.32432      8.25      8.25  10.086148  11.672298      15.0   \n",
       "4   3.450450  37.32432      8.25      8.25  10.113175  11.726352      15.0   \n",
       "\n",
       "    tmin_jun   tmin_jul  tmin_aug   tmin_sep   tmin_oct  tmin_nov  tmin_dec  \\\n",
       "0  18.005068  21.010136      22.0  18.255068  16.755068     13.25  6.760135   \n",
       "1  18.032095  21.064190      22.0  18.282095  16.782095     13.25  6.814189   \n",
       "2  18.059122  21.118244      22.0  18.309122  16.809122     13.25  6.868243   \n",
       "3  18.086150  21.172297      22.0  18.336150  16.836150     13.25  6.922297   \n",
       "4  18.113176  21.226350      22.0  18.363176  16.863176     13.25  6.976351   \n",
       "\n",
       "   is_fire  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_climate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9351163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_climate_df.shape\n",
    "(fire_climate_df['is_fire'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb06d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ REPRESENT ALL FIRES:\n",
      "   Total fires: 12,924\n",
      "   Successfully assigned: 12,924\n",
      "   Unassigned fires: 0\n",
      "   Fire-affected grid points: 2,582\n",
      "   Assignment rate: 100.0%\n"
     ]
    }
   ],
   "source": [
    "climate_fire = represent_all_fires(r\"D:\\S3\\data_mining\\projet2\\temperature_2km_grid.csv\" , r\"D:\\S3\\data_mining\\projet\\clean_data\\fire_alg_tunis.csv\" , \"fire_climate1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cbc692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_fire = pd.read_csv(r\"D:\\S3\\data_mining\\projet2\\final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33072a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(698106, 39)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_fire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e51eecb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6353)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(climate_fire[\"is_fire\"] == 1).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
